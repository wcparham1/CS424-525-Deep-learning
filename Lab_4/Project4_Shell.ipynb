{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2adb05c1",
   "metadata": {},
   "source": [
    "# Project 4\n",
    "## Students:\n",
    " > Abdurhman Bahour,\n",
    " > Coby White,\n",
    " > William C. Parham\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "563a5a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b2ebf08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)# you may want to upgrade to 2.10.0 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17a95a42",
   "metadata": {},
   "source": [
    "### Please Use Markdown\n",
    "> for markdown, see here: https://www.ibm.com/docs/en/watson-studio-local/1.2.3?topic=notebooks-markdown-jupyter-cheatsheet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddae40d9",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "8ee6cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel():\n",
    "    def __init__(self, vocab_size, embed_dim=256, num_heads=2, num_blocks=1, ff_dim=256, maxlen=64, rate=0.1):\n",
    "        #initailize variables\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads    #Use with transformerblock function\n",
    "        self.num_blocks = num_blocks\n",
    "        self.ff_dim = ff_dim\n",
    "        self.maxlen = maxlen\n",
    "        self.rate = rate              #Use with dropout layer creation\n",
    "\n",
    "    def TransformerBlock(self, inputs):\n",
    "        #create the transformer block as discribed in the writeup, use the Keras functional API (https://keras.io/guides/functional_api/)\n",
    "        #add the inputs which should be a positional embedding and token embedding\n",
    "       \n",
    "        #MultiHeadAttention layer, specifiy 'use_causal_mask=True' (https://keras.io/api/layers/attention_layers/multi_head_attention/)\n",
    "        # layer_1 = layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=, use_casual_mask=True)(input_tensor)\n",
    "        layer_1 = layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.embed_dim, use_bias=False, dropout=self.rate, name='layer_1')(inputs, inputs, use_causal_mask=True)\n",
    "\n",
    "        # layer_1 = layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.embed_dim, use_bias=False, use_casual_mask=True, dropout=self.rate, name='multi_head_attention')(input_tensor)\n",
    "        #Use the rate variable for the dropout layers\n",
    "        layer_2 = layers.Dropout(rate=self.rate, name='layer_2')(layer_1)\n",
    "        \n",
    "        #adder layer, output of prev dropout and input tensor\n",
    "        layer_adder = layers.Add()([layer_2, inputs])\n",
    "        \n",
    "        #LayerNormalization layer, specifiy 'epsilon=1e-6' (https://keras.io/api/layers/normalization_layers/layer_normalization/)\n",
    "        layer_3 = layers.LayerNormalization(epsilon=1e-6, name='layer_3')(layer_adder)\n",
    "        \n",
    "        #first dense layer\n",
    "        layer_4 = layers.Dense(units=self.ff_dim, name='layer_4', activation = 'relu')(layer_3)\n",
    "        \n",
    "        #second dense layer\n",
    "        layer_5 = layers.Dense(units=self.ff_dim, name='layer_5')(layer_4)\n",
    "        \n",
    "        #dropout layer\n",
    "        layer_6 = layers.Dropout(rate=self.rate, name='layer_6')(layer_5)\n",
    "        \n",
    "        #adder layer, output of previous dropout and layer layer normalization layer\n",
    "        layer_adder_2 = layers.Add()([layer_3 + layer_6])\n",
    "        \n",
    "        #output layer, final layer normalization layer\n",
    "        output_layer = layers.LayerNormalization(epsilon=1e-6, name='output_layer')(layer_adder_2)\n",
    "        \n",
    "        return output_layer\n",
    "        \n",
    "    def EmbeddingLayer(self, inputs):\n",
    "            \n",
    "        #create the embedding layer\n",
    "        #create (1) an embedding for the tokens and (2) an embedding for the positions\n",
    "        #you can use https://keras.io/api/layers/core_layers/embedding/ Embedding class\n",
    "        #you can use tf.range to enocde positions\n",
    "        #add (1) and (2) and return the layer\n",
    "\n",
    "        # return layers.Add(name='embedding')([layers.Embedding(input_dim=self.vocab_size, output_dim=self.embed_dim, name='token_embedding')(inputs) + layers.Embedding(input_dim=self.maxlen, output_dim=self.embed_dim, name='pos_embedding')(tf.range(start=0, limit=self.maxlen, delta=1))])\n",
    "\n",
    "        # Define the token embedding layer\n",
    "        token_embedding_layer = layers.Embedding(input_dim=self.vocab_size, output_dim=self.embed_dim, name='token_embedding_layer')(inputs)\n",
    "\n",
    "        # Define the positional embedding layer\n",
    "        position_embedding_layer = layers.Embedding(input_dim=self.maxlen, output_dim=self.embed_dim, name='position_embedding_layer')(tf.range(start=0, limit=self.maxlen, delta=1))\n",
    "\n",
    "        # Combine the token embedding and positional embedding layers\n",
    "        combined_embedding_layer = layers.Add()([token_embedding_layer + position_embedding_layer])\n",
    "\n",
    "        return combined_embedding_layer\n",
    "    \n",
    "    def create_model(self):\n",
    "        \n",
    "        #combine the EmbeddingLayer and num_blocks TransformerBlocks to create the model, use the Keras functional API (https://keras.io/guides/functional_api/)\n",
    "        #See the section on the functional API link \"All models are callabe, just like layers\" for code refernce\n",
    "        transformer_input = keras.Input(shape=self.maxlen,  name='inputs')\n",
    "        embed_block = self.EmbeddingLayer(inputs=transformer_input)\n",
    "        transformer_block = embed_block\n",
    "        for _ in range(self.num_blocks):\n",
    "            transformer_block = self.TransformerBlock(inputs=transformer_block)\n",
    "\n",
    "        output_dense = layers.Dense(units=self.vocab_size, activation='softmax', name='output_dense')(transformer_block)\n",
    "        model = Model(inputs=transformer_input, outputs=output_dense)\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # model.summary()\n",
    "        return model\n",
    "        #use the SparseCategoricalCrossentropy loss function (https://keras.io/api/losses/probabilistic_losses/#sparsecategoricalcrossentropy-class)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5ad747b",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "227111a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self, filename, seq_len):\n",
    "        with open(filename, 'r') as f:\n",
    "            self.text = f.read()\n",
    "        self.seq_len = seq_len\n",
    "        self.vocab = None\n",
    "        self.tokenized_text = None\n",
    "\n",
    "    def prep_text(self):\n",
    "        self.text = re.sub(r'[^a-zA-Z\\s]', ' ', self.text)  # remove everything except letters and spaces\n",
    "        self.text = self.text.lower()\n",
    "        self.text = re.sub(r'\\s+', ' ', self.text)  # remove duplicate spaces\n",
    "        self.text = self.text.replace('\\t', ' ')  # replace tabs with spaces\n",
    "        self.text = self.text.split()\n",
    "        \n",
    "    def tokenize_text(self):\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts([self.text])\n",
    "        self.vocab = np.unique(self.text)\n",
    "        self.tokenized_text  = [np.where(self.vocab == word)[0][0] for word in self.text]\n",
    "\n",
    "    def create_dataset(self):\n",
    "        # Preprocess the text\n",
    "        self.prep_text()\n",
    "        self.tokenize_text()\n",
    "\n",
    "        # Split the tokenized data into sequences of length len\n",
    "        num_seq = int(len(self.text) // self.seq_len)\n",
    "        print(num_seq)\n",
    "        x = [self.tokenized_text[i*self.seq_len:(i+1)*self.seq_len] for i in range(num_seq)]\n",
    "        y = [self.tokenized_text[(i*self.seq_len)+1:((i+1)*self.seq_len)+1] for i in range(num_seq)]\n",
    "\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        print(\"x: \", x.shape)\n",
    "        print(\"y: \", y.shape)\n",
    "        print(\"vocab: \", self.vocab)\n",
    "\n",
    "        return x, y, self.vocab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39c3a399",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "6ffe1274",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateText():\n",
    "    def __init__(self, model, vocab):\n",
    "    # The init method will instantiates the reference to the model and vocabulary. It\n",
    "    # also create a mapping from the integer representation of tokens/words into a\n",
    "    # human-readable format.\n",
    "        self.model = model\n",
    "        self.vocab = vocab\n",
    "        self.int_to_vocab = dict(enumerate(self.vocab))\n",
    "        self.vocab_to_int = {self.int_to_vocab[i]: i for i in self.int_to_vocab}\n",
    "    \n",
    "        print(\"vocab: \", self.vocab)\n",
    "        print(\"int_to_vocab: \", self.int_to_vocab)\n",
    "        print(\"vocab_to_int: \", self.vocab_to_int)\n",
    "\n",
    "    def generate_text(self, start_string, num_generate=100):\n",
    "        #start_tokens = [_ for _ in start_string]\n",
    "        print('this is start_string: ', start_string)\n",
    "        start_tokens = [self.vocab_to_int[word] for word in start_string.split()]\n",
    "\n",
    "        print('this is start_tokens: ', start_tokens)\n",
    "        \n",
    "        maxlen = 64\n",
    "        num_tokens_generated = 0\n",
    "        tokens_generated = []\n",
    "        txt = start_string + ' '\n",
    "        while num_tokens_generated <= num_generate:\n",
    "            pad_len = maxlen - len(start_tokens)\n",
    "            sample_index = len(start_tokens) - 1\n",
    "            if pad_len < 0:\n",
    "                x = start_tokens[:maxlen]\n",
    "                sample_index = maxlen - 1\n",
    "            elif pad_len > 0:\n",
    "                x = start_tokens + [0] * pad_len\n",
    "            else:\n",
    "                x = start_tokens\n",
    "\n",
    "            x = np.array([x])\n",
    "            print(\"this is x: \", x)\n",
    "            # print(\"shape of x: \", x.shape)\n",
    "            # y,_ = self.model.predict(x)  #THE ERROR IS HAPPENING HERE -- github is saying it may be a dimensionality error in pytorch ... we are using keras.\n",
    "            y = self.model.predict(x)\n",
    "            # print('this is the shape: ', y.shape)\n",
    "            # print('this is y[0][sample_index]: \\n', y[0][sample_index])\n",
    "            #sample_token = self.generate_random_text(y[0][sample_index])\n",
    "            # sample_token = self.sample_from(y[0][sample_index])\n",
    "            y = np.array(y)\n",
    "            \n",
    "            #look through each row and column and argmax the row then find the corresponding value\n",
    "            #the position in each list will reflect \n",
    "\n",
    "            argmaxes = []\n",
    "            for i in range(0, len(y)):\n",
    "                for j in range(0, len(y[i])):\n",
    "                    argmaxes.append(np.argmax(y[i][j]))\n",
    "            \n",
    "            print('argmaxes: \\n', argmaxes)\n",
    "            #print('argmax of argmaxes: ', np.argmax(np.array(argmaxes)))\n",
    "            print('argmaxes[np.argmax(np.array(argmaxes))]:', argmaxes[np.argmax(np.array(argmaxes))])\n",
    "            best_token = self.vocab[argmaxes[np.argmax(np.array(argmaxes))]]\n",
    "            tokens_generated.append(best_token)\n",
    "            start_tokens.append(self.vocab_to_int[best_token])\n",
    "            print('best token: ', best_token, '\\n',\n",
    "                  'start_tokens: ', start_tokens, '\\n', \n",
    "                  'token_generated: ', tokens_generated)\n",
    "            num_tokens_generated = len(tokens_generated)\n",
    "            txt = txt + best_token + ' '\n",
    "\n",
    "            # print(f\"generated text:\\n{txt}\\n\")\n",
    "            print('generated text: ', txt)\n",
    "        # # Initialize the start sequence\n",
    "        # input_eval = [self.vocab_to_int[word] for word in start_string.split()]\n",
    "        # # input_eval = tf.expand_dims(input_eval, 0)\n",
    "        \n",
    "        # # Initialize the generated text\n",
    "        # generated_text = []\n",
    "        \n",
    "        # X = np.array(input_eval)\n",
    "        \n",
    "        # # Loop through the specified number of words to generate\n",
    "        # for i in range(num_generate):\n",
    "        #     print(\"GenerateText.generate_text() input_eval: \", [input_eval])\n",
    "        #     # Predict the next word using the trained model\n",
    "        #     predictions = self.model.predict(X)\n",
    "        #     # predictions = tf.squeeze(predictions, 0)\n",
    "        #     predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "            \n",
    "        #     # Add the predicted word to the generated text\n",
    "        #     generated_text.append(self.reverse_vocab[predicted_id])\n",
    "            \n",
    "        #     # Update the input sequence for the next iteration\n",
    "        #     input_eval = tf.expand_dims([predicted_id], 0)\n",
    "            \n",
    "        # # Join the generated text into a single string and return it\n",
    "        # return ' '.join(generated_text)\n",
    "\n",
    "        \n",
    "    # def generate_text(self, start_string, num_generate=100):\n",
    "    #     # preprocess start string\n",
    "    #     print(\"GenerateText.generate_text() Start String: \", start_string)\n",
    "    #     tokenized_start_string = [self.vocab_to_int[i] for i in start_string.split()]\n",
    "\n",
    "    #     # initialize generated text\n",
    "    #     generated_text = []\n",
    "        \n",
    "     \n",
    "    #     # for i in range(num_generate):\n",
    "    #     #     # get predictions from model\n",
    "    #     #     predictions = self.model(tokenized_start_string)\n",
    "    #     #     predictions = tf.squeeze(predictions, 0)\n",
    "            \n",
    "    #     #     print(\"predictions: \", predictions)\n",
    "\n",
    "    #     #     # apply softmax to predictions and sample index from distribution\n",
    "    #     #     predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "            \n",
    "    #     #     # add predicted word to generated text and update input_eval\n",
    "    #     #     generated_text.append(self.vocab_to_int[predicted_id])\n",
    "    #     #     input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    #     for i in range(num_generate):\n",
    "    #         # Tokenize the start string\n",
    "    #         # Pad the start string\n",
    "            \n",
    "    #         print(\"tokenized_start_string: \", tokenized_start_string)\n",
    "            \n",
    "    #         np_tokenized = np.array(tokenized_start_string)\n",
    "    #         print(\"np_tokenized: \", np_tokenized)\n",
    "\n",
    "    #         tokenized_reshaped = np.reshape(np_tokenized, (np_tokenized.shape[0],1))\n",
    "    #         print(\"tokenized_reshaped: \", tokenized_reshaped)\n",
    "\n",
    "    #         tokenized_start_string = tf.keras.preprocessing.sequence.pad_sequences(np_tokenized, maxlen=64, padding='post')\n",
    "    #         # Predict the next word\n",
    "    #         predicted_word = self.model.predict(tokenized_start_string)\n",
    "    #         # Add the predicted word to the start string\n",
    "    #         start_string += self.int_to_vocab[predicted_word]   \n",
    "\n",
    "    #         # print(\"generated_text: \", generated_text)\n",
    "    #         # print(\"input_eval: \", input_eval)\n",
    "    #         # print(\"predicted_id: \", predicted_id)\n",
    "    #         # print(\"predictions: \", predictions)\n",
    "    #         # print(\"start_string: \", start_string)\n",
    "    #     return start_string + ' ' + ' '.join(generated_text)\n",
    "    \n",
    "    def generate_random_text(self, start_string='', num_generate=100):\n",
    "        # initialize generated text\n",
    "        generated_text = []\n",
    "        \n",
    "        # loop to generate text\n",
    "        for i in range(num_generate):\n",
    "            # get random word from vocab\n",
    "            predicted_word = np.random.choice(self.vocab)\n",
    "            \n",
    "            # add predicted word to generated text\n",
    "            generated_text.append(predicted_word)\n",
    "            \n",
    "        # print(\"generated_text: \", ' '.join(generated_text))\n",
    "        word = ' '.join(generated_text)\n",
    "        \n",
    "        print('This is start string and len: ', len(start_string), ' ', start_string, '\\n', 'This is word and len: ',len(word), word)\n",
    "        return start_string + ' ' + word\n",
    "        #return ' ' + word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "17240265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = train_model(model,x[:64,:],y[:64,:],vocab,epochs=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edd0bd9d",
   "metadata": {},
   "source": [
    "## Task 4: Model Traning and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "1b59dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model while periodically generating text to show progress\n",
    "def train_model(model, x, y, vocab, epochs=50):\n",
    "    # Generate text\n",
    "    GT = GenerateText(model, vocab)\n",
    "    random_text = \"zapped\"\n",
    "    for e in range(epochs):\n",
    "        print(f\"Epoch {e+1}\")\n",
    "        # Train the model\n",
    "        model.fit(x, y, epochs=1, batch_size=64, verbose=1)\n",
    "\n",
    "        # # # Generate text\n",
    "        # random_text = GT.generate_random_text(random_text)\n",
    "        # print(\"random_text: \", random_text)\n",
    "        random_text = GT.generate_text(random_text)  #doenst get past here\n",
    "        print(\"random_text: \", random_text)\n",
    "\n",
    "        # random_text = GenerateText.generate_random_text(100)\n",
    "\n",
    "    print(\"Betal Song:\", random_text)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "de5537ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564\n",
      "x:  (564, 64)\n",
      "y:  (564, 64)\n",
      "vocab:  ['a' 'aaaaaaaahhhh' 'aaaaaahhhhhh' ... 'zapped' 'zoo' 'zu']\n",
      "len(vocab): 2491\n",
      "vocab:  ['a' 'aaaaaaaahhhh' 'aaaaaahhhhhh' ... 'zapped' 'zoo' 'zu']\n",
      "int_to_vocab:  {0: 'a', 1: 'aaaaaaaahhhh', 2: 'aaaaaahhhhhh', 3: 'aaaaahhhhhhhhhh', 4: 'aaaah', 5: 'aaahhh', 6: 'able', 7: 'about', 8: 'above', 9: 'abrigado', 10: 'accidents', 11: 'aches', 12: 'acorns', 13: 'acquainted', 14: 'across', 15: 'act', 16: 'acts', 17: 'admit', 18: 'advice', 19: 'affection', 20: 'afraid', 21: 'after', 22: 'afternoon', 23: 'again', 24: 'against', 25: 'age', 26: 'ago', 27: 'agree', 28: 'ah', 29: 'ahead', 30: 'ain', 31: 'air', 32: 'al', 33: 'albert', 34: 'alerted', 35: 'all', 36: 'allan', 37: 'allein', 38: 'alley', 39: 'almost', 40: 'alone', 41: 'along', 42: 'aloud', 43: 'already', 44: 'alright', 45: 'although', 46: 'always', 47: 'am', 48: 'american', 49: 'amore', 50: 'amsterdam', 51: 'an', 52: 'and', 53: 'andern', 54: 'angel', 55: 'angry', 56: 'anna', 57: 'annoyed', 58: 'another', 59: 'answer', 60: 'any', 61: 'anybody', 62: 'anyhow', 63: 'anymore', 64: 'anyone', 65: 'anything', 66: 'anytime', 67: 'anyway', 68: 'anywhere', 69: 'apart', 70: 'apologize', 71: 'appear', 72: 'appears', 73: 'apple', 74: 'appointment', 75: 'appreciate', 76: 'are', 77: 'aren', 78: 'arise', 79: 'arizona', 80: 'armchair', 81: 'armen', 82: 'arms', 83: 'army', 84: 'around', 85: 'arrive', 86: 'arrives', 87: 'arriving', 88: 'as', 89: 'ask', 90: 'asked', 91: 'asking', 92: 'asleep', 93: 'assure', 94: 'assured', 95: 'at', 96: 'ate', 97: 'atlantic', 98: 'attractively', 99: 'attracts', 100: 'audience', 101: 'aunt', 102: 'avoid', 103: 'awake', 104: 'aware', 105: 'away', 106: 'awoke', 107: 'awoken', 108: 'ay', 109: 'b', 110: 'ba', 111: 'babe', 112: 'baby', 113: 'back', 114: 'backdoor', 115: 'backed', 116: 'backing', 117: 'bacon', 118: 'bad', 119: 'badly', 120: 'bag', 121: 'bags', 122: 'balalaika', 123: 'ball', 124: 'ballad', 125: 'band', 126: 'bang', 127: 'banker', 128: 'banks', 129: 'barber', 130: 'barrow', 131: 'based', 132: 'bath', 133: 'bathroom', 134: 'bb', 135: 'bbbbb', 136: 'bbc', 137: 'be', 138: 'beach', 139: 'beam', 140: 'beat', 141: 'beatin', 142: 'beautiful', 143: 'beauty', 144: 'became', 145: 'because', 146: 'becomes', 147: 'bed', 148: 'bedroom', 149: 'beds', 150: 'bee', 151: 'been', 152: 'beep', 153: 'bees', 154: 'beethoven', 155: 'before', 156: 'beg', 157: 'begged', 158: 'beggin', 159: 'begging', 160: 'begin', 161: 'begings', 162: 'beginning', 163: 'begins', 164: 'behave', 165: 'behind', 166: 'bei', 167: 'being', 168: 'bejust', 169: 'believe', 170: 'believing', 171: 'bell', 172: 'belle', 173: 'bells', 174: 'bellyful', 175: 'belong', 176: 'belonged', 177: 'below', 178: 'bended', 179: 'beneath', 180: 'benefit', 181: 'bent', 182: 'beside', 183: 'best', 184: 'bet', 185: 'better', 186: 'between', 187: 'beyond', 188: 'bible', 189: 'biding', 190: 'bien', 191: 'big', 192: 'bigger', 193: 'biggest', 194: 'bill', 195: 'billy', 196: 'bin', 197: 'bird', 198: 'birds', 199: 'birthday', 200: 'bishopsgate', 201: 'bist', 202: 'bit', 203: 'bits', 204: 'bla', 205: 'black', 206: 'blackbird', 207: 'blackburn', 208: 'blame', 209: 'blew', 210: 'blind', 211: 'blindly', 212: 'blink', 213: 'bloody', 214: 'blow', 215: 'blowin', 216: 'blows', 217: 'blue', 218: 'blues', 219: 'boac', 220: 'board', 221: 'boat', 222: 'bob', 223: 'bone', 224: 'book', 225: 'booked', 226: 'books', 227: 'boom', 228: 'bootlace', 229: 'boots', 230: 'bop', 231: 'born', 232: 'both', 233: 'bother', 234: 'bottle', 235: 'bottom', 236: 'bought', 237: 'bound', 238: 'bounder', 239: 'bout', 240: 'box', 241: 'boy', 242: 'boyfriend', 243: 'boys', 244: 'bra', 245: 'brain', 246: 'brand', 247: 'break', 248: 'breakfast', 249: 'breaking', 250: 'breaks', 251: 'breast', 252: 'brew', 253: 'bride', 254: 'bridge', 255: 'bright', 256: 'bring', 257: 'bringing', 258: 'brings', 259: 'broke', 260: 'broken', 261: 'brother', 262: 'brown', 263: 'built', 264: 'bulldog', 265: 'bullet', 266: 'bullfrog', 267: 'bundle', 268: 'bungalow', 269: 'buried', 270: 'burning', 271: 'burns', 272: 'burst', 273: 'bus', 274: 'busby', 275: 'business', 276: 'busy', 277: 'but', 278: 'butted', 279: 'butterflies', 280: 'buy', 281: 'buys', 282: 'by', 283: 'bye', 284: 'c', 285: 'cake', 286: 'california', 287: 'call', 288: 'called', 289: 'calling', 290: 'calls', 291: 'came', 292: 'can', 293: 'canary', 294: 'canite', 295: 'cannot', 296: 'cap', 297: 'captain', 298: 'car', 299: 'carat', 300: 'carathon', 301: 'card', 302: 'care', 303: 'cares', 304: 'caressing', 305: 'carousel', 306: 'carry', 307: 'carrying', 308: 'carve', 309: 'case', 310: 'cast', 311: 'cat', 312: 'catch', 313: 'caught', 314: 'cause', 315: 'cave', 316: 'ceiling', 317: 'celebrate', 318: 'celebrated', 319: 'celebrations', 320: 'cellophane', 321: 'cent', 322: 'certain', 323: 'certainly', 324: 'cha', 325: 'chain', 326: 'chains', 327: 'chair', 328: 'chairman', 329: 'challenge', 330: 'chance', 331: 'chances', 332: 'change', 333: 'changed', 334: 'changes', 335: 'changing', 336: 'charity', 337: 'chasing', 338: 'cheat', 339: 'check', 340: 'checked', 341: 'cherry', 342: 'child', 343: 'children', 344: 'childrens', 345: 'chip', 346: 'chocolate', 347: 'choking', 348: 'choose', 349: 'chords', 350: 'chorus', 351: 'christ', 352: 'chuck', 353: 'church', 354: 'cia', 355: 'cicce', 356: 'cigarette', 357: 'city', 358: 'class', 359: 'clean', 360: 'clear', 361: 'climb', 362: 'climbing', 363: 'clinging', 364: 'clock', 365: 'close', 366: 'closed', 367: 'closer', 368: 'closing', 369: 'clothes', 370: 'cloud', 371: 'clouds', 372: 'cloudy', 373: 'clown', 374: 'clowns', 375: 'club', 376: 'clubs', 377: 'clue', 378: 'clutching', 379: 'coaster', 380: 'coat', 381: 'coca', 382: 'cocker', 383: 'coconut', 384: 'coffee', 385: 'cola', 386: 'cold', 387: 'colder', 388: 'collapsed', 389: 'college', 390: 'colour', 391: 'colourful', 392: 'comb', 393: 'come', 394: 'comes', 395: 'comfort', 396: 'coming', 397: 'command', 398: 'compare', 399: 'compares', 400: 'complainin', 401: 'comrade', 402: 'conceive', 403: 'confusing', 404: 'congo', 405: 'constitution', 406: 'continuing', 407: 'contribution', 408: 'controlled', 409: 'conversation', 410: 'cooking', 411: 'cool', 412: 'coral', 413: 'corner', 414: 'cornflake', 415: 'corporation', 416: 'correct', 417: 'cos', 418: 'cottage', 419: 'could', 420: 'couldn', 421: 'count', 422: 'country', 423: 'couple', 424: 'course', 425: 'cows', 426: 'crabalocker', 427: 'cracker', 428: 'cracks', 429: 'crash', 430: 'crawled', 431: 'crawling', 432: 'crazy', 433: 'cream', 434: 'creep', 435: 'creeps', 436: 'creme', 437: 'cried', 438: 'cries', 439: 'crime', 440: 'cross', 441: 'crossed', 442: 'crowd', 443: 'crucify', 444: 'cruel', 445: 'cry', 446: 'crying', 447: 'cummin', 448: 'cup', 449: 'curse', 450: 'custard', 451: 'customer', 452: 'cut', 453: 'cuts', 454: 'd', 455: 'da', 456: 'daddy', 457: 'daily', 458: 'daises', 459: 'daisy', 460: 'dakota', 461: 'damn', 462: 'dan', 463: 'dance', 464: 'danced', 465: 'dancer', 466: 'dances', 467: 'dancin', 468: 'daniel', 469: 'dann', 470: 'danny', 471: 'daran', 472: 'dark', 473: 'darkness', 474: 'darlin', 475: 'darling', 476: 'darn', 477: 'darning', 478: 'das', 479: 'date', 480: 'dave', 481: 'dawn', 482: 'day', 483: 'daya', 484: 'days', 485: 'de', 486: 'dead', 487: 'dear', 488: 'deceive', 489: 'decide', 490: 'declare', 491: 'deep', 492: 'deeper', 493: 'deine', 494: 'deinen', 495: 'delay', 496: 'deliver', 497: 'demonstrate', 498: 'den', 499: 'denied', 500: 'denis', 501: 'denkt', 502: 'denn', 503: 'deny', 504: 'department', 505: 'desert', 506: 'deserve', 507: 'desmond', 508: 'dessert', 509: 'destruction', 510: 'determined', 511: 'devil', 512: 'di', 513: 'diamant', 514: 'diamond', 515: 'diamonds', 516: 'dich', 517: 'did', 518: 'didididi', 519: 'didn', 520: 'die', 521: 'died', 522: 'dies', 523: 'difference', 524: 'different', 525: 'differnt', 526: 'dig', 527: 'digging', 528: 'diller', 529: 'dime', 530: 'dinner', 531: 'dir', 532: 'direction', 533: 'dirt', 534: 'dirty', 535: 'disagree', 536: 'disappear', 537: 'disappearing', 538: 'disappointment', 539: 'disconnect', 540: 'discovered', 541: 'discreetly', 542: 'disease', 543: 'diverted', 544: 'dizzy', 545: 'dna', 546: 'do', 547: 'doc', 548: 'doch', 549: 'dock', 550: 'doctor', 551: 'does', 552: 'doesn', 553: 'dog', 554: 'doggone', 555: 'doing', 556: 'don', 557: 'donated', 558: 'done', 559: 'door', 560: 'doors', 561: 'doris', 562: 'dose', 563: 'doubt', 564: 'doubted', 565: 'dove', 566: 'down', 567: 'downstairs', 568: 'draems', 569: 'drag', 570: 'dragged', 571: 'drank', 572: 'dreadful', 573: 'dream', 574: 'dreaming', 575: 'dreams', 576: 'drehtest', 577: 'dressed', 578: 'dresses', 579: 'dressing', 580: 'drew', 581: 'drift', 582: 'drifting', 583: 'drink', 584: 'drinkin', 585: 'drinking', 586: 'dripping', 587: 'drive', 588: 'driver', 589: 'driving', 590: 'drop', 591: 'drove', 592: 'dry', 593: 'du', 594: 'duchess', 595: 'ducked', 596: 'dug', 597: 'duke', 598: 'duty', 599: 'dying', 600: 'dylan', 601: 'e', 602: 'each', 603: 'eagle', 604: 'ear', 605: 'early', 606: 'earn', 607: 'earned', 608: 'ears', 609: 'earth', 610: 'ease', 611: 'easy', 612: 'eat', 613: 'eating', 614: 'edgar', 615: 'edih', 616: 'edison', 617: 'ee', 618: 'eggman', 619: 'eggmen', 620: 'eh', 621: 'eht', 622: 'eiffel', 623: 'eight', 624: 'ein', 625: 'einer', 626: 'einmal', 627: 'eleanor', 628: 'elementary', 629: 'elephant', 630: 'elephants', 631: 'else', 632: 'em', 633: 'end', 634: 'endear', 635: 'ending', 636: 'endless', 637: 'ends', 638: 'ene', 639: 'engaged', 640: 'engine', 641: 'england', 642: 'english', 643: 'enjoy', 644: 'enjoyed', 645: 'enough', 646: 'ensemble', 647: 'entschuldigst', 648: 'equal', 649: 'equipped', 650: 'es', 651: 'escaping', 652: 'eternally', 653: 'ev', 654: 'even', 655: 'evening', 656: 'ever', 657: 'evermore', 658: 'every', 659: 'everybody', 660: 'everyday', 661: 'everyone', 662: 'everything', 663: 'everywhere', 664: 'evolution', 665: 'exactly', 666: 'except', 667: 'existence', 668: 'expert', 669: 'eye', 670: 'eyeball', 671: 'eyes', 672: 'f', 673: 'face', 674: 'faces', 675: 'fade', 676: 'faded', 677: 'fair', 678: 'fall', 679: 'falling', 680: 'famous', 681: 'fancy', 682: 'fanques', 683: 'far', 684: 'fare', 685: 'farm', 686: 'farther', 687: 'fast', 688: 'faster', 689: 'fate', 690: 'father', 691: 'fbi', 692: 'fears', 693: 'feat', 694: 'featuring', 695: 'fed', 696: 'feed', 697: 'feel', 698: 'feelin', 699: 'feeling', 700: 'feelings', 701: 'feels', 702: 'feet', 703: 'felice', 704: 'fell', 705: 'fever', 706: 'few', 707: 'fi', 708: 'fiddle', 709: 'field', 710: 'fields', 711: 'fierce', 712: 'fifty', 713: 'fight', 714: 'fighting', 715: 'fil', 716: 'fill', 717: 'filled', 718: 'filling', 719: 'film', 720: 'filter', 721: 'finally', 722: 'find', 723: 'finds', 724: 'fine', 725: 'finger', 726: 'fingertips', 727: 'fire', 728: 'fireman', 729: 'fireside', 730: 'first', 731: 'fish', 732: 'fishwife', 733: 'five', 734: 'fix', 735: 'fixing', 736: 'flat', 737: 'flattop', 738: 'flew', 739: 'flies', 740: 'flight', 741: 'flirt', 742: 'float', 743: 'floating', 744: 'floor', 745: 'flowers', 746: 'flowing', 747: 'flown', 748: 'flows', 749: 'fly', 750: 'flys', 751: 'fog', 752: 'fold', 753: 'folks', 754: 'follow', 755: 'fool', 756: 'foolin', 757: 'fooling', 758: 'foolish', 759: 'foot', 760: 'football', 761: 'footsteps', 762: 'for', 763: 'fore', 764: 'forever', 765: 'forget', 766: 'forgive', 767: 'forgotten', 768: 'forks', 769: 'form', 770: 'found', 771: 'fountain', 772: 'four', 773: 'fragrant', 774: 'france', 775: 'frantic', 776: 'free', 777: 'freely', 778: 'freu', 779: 'friday', 780: 'friend', 781: 'friends', 782: 'frightened', 783: 'froh', 784: 'from', 785: 'front', 786: 'frown', 787: 'fudge', 788: 'full', 789: 'fun', 790: 'funny', 791: 'fuse', 792: 'fussing', 793: 'future', 794: 'g', 795: 'gain', 796: 'gallery', 797: 'game', 798: 'games', 799: 'gar', 800: 'garden', 801: 'garters', 802: 'gas', 803: 'gather', 804: 'gave', 805: 'gear', 806: 'gee', 807: 'gehen', 808: 'gently', 809: 'george', 810: 'georgia', 811: 'gesehen', 812: 'gestern', 813: 'get', 814: 'getan', 815: 'gets', 816: 'getter', 817: 'getting', 818: 'gib', 819: 'gibraltar', 820: 'gideon', 821: 'gimme', 822: 'gin', 823: 'ginger', 824: 'girl', 825: 'girlfriend', 826: 'girls', 827: 'give', 828: 'gives', 829: 'givin', 830: 'giving', 831: 'glad', 832: 'glass', 833: 'glaubst', 834: 'glimmering', 835: 'glimpse', 836: 'glow', 837: 'glucklich', 838: 'go', 839: 'goats', 840: 'goes', 841: 'goin', 842: 'going', 843: 'golden', 844: 'gone', 845: 'gonna', 846: 'goo', 847: 'good', 848: 'goodbye', 849: 'goodbyes', 850: 'got', 851: 'gotta', 852: 'gown', 853: 'grabbed', 854: 'grade', 855: 'grandchildren', 856: 'grass', 857: 'grave', 858: 'greatest', 859: 'green', 860: 'greet', 861: 'greetings', 862: 'grin', 863: 'grinning', 864: 'grooving', 865: 'ground', 866: 'grow', 867: 'guaranteed', 868: 'guess', 869: 'guest', 870: 'guilty', 871: 'guitar', 872: 'gum', 873: 'gumboot', 874: 'gun', 875: 'guru', 876: 'gurus', 877: 'guy', 878: 'h', 879: 'hab', 880: 'habit', 881: 'had', 882: 'hai', 883: 'hair', 884: 'haired', 885: 'half', 886: 'hall', 887: 'hammer', 888: 'hand', 889: 'hands', 890: 'handy', 891: 'hang', 892: 'hanging', 893: 'hankerchief', 894: 'happen', 895: 'happened', 896: 'happens', 897: 'happiness', 898: 'happinness', 899: 'happy', 900: 'hard', 901: 'hardly', 902: 'hari', 903: 'harm', 904: 'harmony', 905: 'has', 906: 'hast', 907: 'hat', 908: 'hate', 909: 'hates', 910: 'have', 911: 'haven', 912: 'havin', 913: 'having', 914: 'hay', 915: 'haze', 916: 'he', 917: 'head', 918: 'headed', 919: 'heading', 920: 'heads', 921: 'health', 922: 'hear', 923: 'heard', 924: 'hearing', 925: 'hears', 926: 'heart', 927: 'hearted', 928: 'hearts', 929: 'heat', 930: 'heaven', 931: 'heavy', 932: 'heba', 933: 'heel', 934: 'hela', 935: 'held', 936: 'hello', 937: 'helloa', 938: 'help', 939: 'helping', 940: 'helps', 941: 'helter', 942: 'hendersons', 943: 'henry', 944: 'her', 945: 'here', 946: 'herself', 947: 'hewr', 948: 'hey', 949: 'hi', 950: 'hide', 951: 'hideaway', 952: 'hiding', 953: 'high', 954: 'higher', 955: 'hill', 956: 'hills', 957: 'hilt', 958: 'hilton', 959: 'him', 960: 'himself', 961: 'his', 962: 'hit', 963: 'ho', 964: 'hobnail', 965: 'hoe', 966: 'hog', 967: 'hogshead', 968: 'hold', 969: 'holding', 970: 'hole', 971: 'holes', 972: 'holiday', 973: 'holland', 974: 'hollywood', 975: 'holy', 976: 'home', 977: 'homeward', 978: 'homing', 979: 'honey', 980: 'hoo', 981: 'hoop', 982: 'hoops', 983: 'hope', 984: 'hoped', 985: 'hoping', 986: 'horse', 987: 'horses', 988: 'hot', 989: 'hour', 990: 'hourglass', 991: 'house', 992: 'how', 993: 'however', 994: 'hugs', 995: 'huh', 996: 'hula', 997: 'hum', 998: 'hung', 999: 'hunting', 1000: 'hurricane', 1001: 'hurry', 1002: 'hurt', 1003: 'hurting', 1004: 'husband', 1005: 'i', 1006: 'ice', 1007: 'ich', 1008: 'if', 1009: 'ignorance', 1010: 'ihr', 1011: 'illusion', 1012: 'images', 1013: 'imagine', 1014: 'imagined', 1015: 'imitate', 1016: 'imperfect', 1017: 'important', 1018: 'impression', 1019: 'imprisoned', 1020: 'in', 1021: 'inciting', 1022: 'incredibly', 1023: 'independence', 1024: 'indicate', 1025: 'inner', 1026: 'inquire', 1027: 'insane', 1028: 'insecure', 1029: 'inside', 1030: 'inspiration', 1031: 'instead', 1032: 'institution', 1033: 'into', 1034: 'introduce', 1035: 'inverted', 1036: 'investigation', 1037: 'invitation', 1038: 'inviting', 1039: 'iron', 1040: 'is', 1041: 'isle', 1042: 'isn', 1043: 'it', 1044: 'its', 1045: 'j', 1046: 'ja', 1047: 'jack', 1048: 'jackboots', 1049: 'jai', 1050: 'jam', 1051: 'jamboree', 1052: 'jar', 1053: 'jay', 1054: 'jazz', 1055: 'jealous', 1056: 'jetzt', 1057: 'jewellers', 1058: 'jo', 1059: 'joa', 1060: 'joan', 1061: 'job', 1062: 'jobber', 1063: 'jockey', 1064: 'john', 1065: 'joint', 1066: 'jojo', 1067: 'joke', 1068: 'joker', 1069: 'jokey', 1070: 'jonah', 1071: 'jones', 1072: 'joo', 1073: 'joob', 1074: 'joy', 1075: 'jubilee', 1076: 'jude', 1077: 'judge', 1078: 'jukebox', 1079: 'julia', 1080: 'jump', 1081: 'jungle', 1082: 'junior', 1083: 'just', 1084: 'k', 1085: 'kaleidoscope', 1086: 'kann', 1087: 'kansas', 1088: 'kave', 1089: 'keep', 1090: 'keeping', 1091: 'keeps', 1092: 'kept', 1093: 'key', 1094: 'kick', 1095: 'kicking', 1096: 'kid', 1097: 'kids', 1098: 'kill', 1099: 'killer', 1100: 'kilt', 1101: 'kind', 1102: 'kindly', 1103: 'kindness', 1104: 'king', 1105: 'kircaldy', 1106: 'kiss', 1107: 'kissin', 1108: 'kissing', 1109: 'kitchen', 1110: 'kite', 1111: 'knee', 1112: 'knees', 1113: 'knew', 1114: 'knickers', 1115: 'knife', 1116: 'knit', 1117: 'knives', 1118: 'knock', 1119: 'knocking', 1120: 'know', 1121: 'knowing', 1122: 'known', 1123: 'knows', 1124: 'komm', 1125: 'krishna', 1126: 'l', 1127: 'la', 1128: 'lacking', 1129: 'lady', 1130: 'lagoon', 1131: 'lala', 1132: 'lancashire', 1133: 'land', 1134: 'lane', 1135: 'lark', 1136: 'last', 1137: 'lasted', 1138: 'lastly', 1139: 'lasts', 1140: 'latches', 1141: 'late', 1142: 'latest', 1143: 'laugh', 1144: 'laughing', 1145: 'laughs', 1146: 'laughter', 1147: 'laundromat', 1148: 'lay', 1149: 'layed', 1150: 'lazy', 1151: 'lead', 1152: 'leads', 1153: 'lear', 1154: 'learn', 1155: 'learned', 1156: 'learning', 1157: 'learns', 1158: 'leave', 1159: 'leaves', 1160: 'leaving', 1161: 'left', 1162: 'legend', 1163: 'legs', 1164: 'leisure', 1165: 'lemonade', 1166: 'lend', 1167: 'les', 1168: 'less', 1169: 'let', 1170: 'lets', 1171: 'letter', 1172: 'letters', 1173: 'licks', 1174: 'lie', 1175: 'liebt', 1176: 'lied', 1177: 'lies', 1178: 'life', 1179: 'lifetime', 1180: 'lift', 1181: 'lifting', 1182: 'light', 1183: 'lighten', 1184: 'lightning', 1185: 'lights', 1186: 'like', 1187: 'likes', 1188: 'lil', 1189: 'lime', 1190: 'limitless', 1191: 'limousine', 1192: 'line', 1193: 'ling', 1194: 'linger', 1195: 'lingers', 1196: 'lip', 1197: 'lips', 1198: 'listen', 1199: 'listening', 1200: 'lit', 1201: 'little', 1202: 'live', 1203: 'lived', 1204: 'liverpool', 1205: 'lives', 1206: 'living', 1207: 'lizard', 1208: 'lizzie', 1209: 'll', 1210: 'local', 1211: 'location', 1212: 'lock', 1213: 'locked', 1214: 'log', 1215: 'london', 1216: 'lonely', 1217: 'loner', 1218: 'long', 1219: 'longer', 1220: 'look', 1221: 'looked', 1222: 'looking', 1223: 'looks', 1224: 'lords', 1225: 'loretta', 1226: 'lorry', 1227: 'lose', 1228: 'loser', 1229: 'losing', 1230: 'lost', 1231: 'lot', 1232: 'lots', 1233: 'lotta', 1234: 'loud', 1235: 'love', 1236: 'loved', 1237: 'lovely', 1238: 'lover', 1239: 'lovers', 1240: 'loves', 1241: 'lovin', 1242: 'loving', 1243: 'low', 1244: 'luck', 1245: 'lucky', 1246: 'lucy', 1247: 'lullabye', 1248: 'lying', 1249: 'm', 1250: 'ma', 1251: 'mac', 1252: 'machine', 1253: 'mack', 1254: 'mad', 1255: 'madam', 1256: 'made', 1257: 'madly', 1258: 'madonna', 1259: 'mae', 1260: 'magazine', 1261: 'maggie', 1262: 'magic', 1263: 'magical', 1264: 'magil', 1265: 'maid', 1266: 'mail', 1267: 'majesty', 1268: 'majoring', 1269: 'make', 1270: 'makes', 1271: 'making', 1272: 'mama', 1273: 'mambo', 1274: 'man', 1275: 'manage', 1276: 'mantel', 1277: 'many', 1278: 'mao', 1279: 'march', 1280: 'marigold', 1281: 'market', 1282: 'marmalade', 1283: 'married', 1284: 'marry', 1285: 'marshmellow', 1286: 'martha', 1287: 'martin', 1288: 'marvel', 1289: 'mary', 1290: 'mask', 1291: 'match', 1292: 'matchbox', 1293: 'matches', 1294: 'matt', 1295: 'matter', 1296: 'mattered', 1297: 'max', 1298: 'maxwell', 1299: 'may', 1300: 'mayayake', 1301: 'maybe', 1302: 'mckenzie', 1303: 'me', 1304: 'meadows', 1305: 'mean', 1306: 'meander', 1307: 'meaning', 1308: 'meaningless', 1309: 'means', 1310: 'meant', 1311: 'meanwhile', 1312: 'measured', 1313: 'medicine', 1314: 'medley', 1315: 'meet', 1316: 'meeting', 1317: 'melody', 1318: 'melting', 1319: 'memories', 1320: 'men', 1321: 'mending', 1322: 'message', 1323: 'messrs', 1324: 'met', 1325: 'metaphysical', 1326: 'meter', 1327: 'mi', 1328: 'miami', 1329: 'mich', 1330: 'michelle', 1331: 'middle', 1332: 'might', 1333: 'mighty', 1334: 'miles', 1335: 'military', 1336: 'million', 1337: 'mind', 1338: 'minds', 1339: 'mine', 1340: 'minute', 1341: 'mir', 1342: 'mirrors', 1343: 'misery', 1344: 'misplace', 1345: 'miss', 1346: 'missed', 1347: 'misses', 1348: 'missing', 1349: 'mist', 1350: 'mistake', 1351: 'mister', 1352: 'misunderstanding', 1353: 'misunderstood', 1354: 'mit', 1355: 'mmm', 1356: 'mo', 1357: 'moan', 1358: 'modern', 1359: 'mojo', 1360: 'molly', 1361: 'mom', 1362: 'moment', 1363: 'moments', 1364: 'mon', 1365: 'monday', 1366: 'money', 1367: 'monkey', 1368: 'montelimat', 1369: 'mood', 1370: 'moon', 1371: 'mooning', 1372: 'moonlight', 1373: 'more', 1374: 'morining', 1375: 'mornin', 1376: 'morning', 1377: 'mornings', 1378: 'moscow', 1379: 'most', 1380: 'mother', 1381: 'motor', 1382: 'motorcar', 1383: 'mots', 1384: 'mountain', 1385: 'mountains', 1386: 'mourn', 1387: 'move', 1388: 'moved', 1389: 'movement', 1390: 'moves', 1391: 'movies', 1392: 'movin', 1393: 'moving', 1394: 'mr', 1395: 'much', 1396: 'muddy', 1397: 'multicoloured', 1398: 'mundo', 1399: 'music', 1400: 'musst', 1401: 'must', 1402: 'mustard', 1403: 'my', 1404: 'myself', 1405: 'mystery', 1406: 'n', 1407: 'na', 1408: 'naaa', 1409: 'name', 1410: 'named', 1411: 'nananana', 1412: 'nanananaaa', 1413: 'nancy', 1414: 'nasty', 1415: 'nation', 1416: 'national', 1417: 'natural', 1418: 'naturally', 1419: 'nature', 1420: 'naughty', 1421: 'nay', 1422: 'near', 1423: 'nearly', 1424: 'neck', 1425: 'need', 1426: 'needed', 1427: 'needs', 1428: 'negotiations', 1429: 'neighborhood', 1430: 'neighbors', 1431: 'nerve', 1432: 'never', 1433: 'new', 1434: 'news', 1435: 'newspaper', 1436: 'newspapers', 1437: 'next', 1438: 'niar', 1439: 'nice', 1440: 'nicht', 1441: 'nie', 1442: 'night', 1443: 'nights', 1444: 'nighttime', 1445: 'nimmst', 1446: 'nine', 1447: 'nineteen', 1448: 'no', 1449: 'nobody', 1450: 'noch', 1451: 'noise', 1452: 'none', 1453: 'north', 1454: 'northern', 1455: 'norwegian', 1456: 'nose', 1457: 'not', 1458: 'note', 1459: 'nothin', 1460: 'nothing', 1461: 'notice', 1462: 'noticed', 1463: 'novel', 1464: 'now', 1465: 'nowhere', 1466: 'number', 1467: 'nun', 1468: 'nur', 1469: 'nurse', 1470: 'o', 1471: 'oa', 1472: 'oan', 1473: 'ob', 1474: 'obla', 1475: 'oblada', 1476: 'obladi', 1477: 'obscene', 1478: 'ocean', 1479: 'oceanchild', 1480: 'octopus', 1481: 'of', 1482: 'off', 1483: 'often', 1484: 'oh', 1485: 'ohh', 1486: 'ok', 1487: 'ol', 1488: 'old', 1489: 'older', 1490: 'om', 1491: 'on', 1492: 'once', 1493: 'one', 1494: 'onion', 1495: 'only', 1496: 'ono', 1497: 'oo', 1498: 'ooh', 1499: 'oooh', 1500: 'opaque', 1501: 'open', 1502: 'opened', 1503: 'or', 1504: 'orange', 1505: 'oscar', 1506: 'other', 1507: 'ought', 1508: 'oughta', 1509: 'ould', 1510: 'our', 1511: 'ours', 1512: 'ourselves', 1513: 'out', 1514: 'outside', 1515: 'over', 1516: 'overnight', 1517: 'overtime', 1518: 'ow', 1519: 'own', 1520: 'owned', 1521: 'owww', 1522: 'p', 1523: 'pablo', 1524: 'pages', 1525: 'paid', 1526: 'pain', 1527: 'painting', 1528: 'pam', 1529: 'pane', 1530: 'paparazzi', 1531: 'paper', 1532: 'paperback', 1533: 'papers', 1534: 'paramucho', 1535: 'parasol', 1536: 'paris', 1537: 'park', 1538: 'parking', 1539: 'parlour', 1540: 'part', 1541: 'parted', 1542: 'partner', 1543: 'party', 1544: 'pass', 1545: 'passed', 1546: 'past', 1547: 'patiently', 1548: 'paul', 1549: 'pay', 1550: 'peace', 1551: 'peaches', 1552: 'peaked', 1553: 'peanuts', 1554: 'peasant', 1555: 'peep', 1556: 'penetrate', 1557: 'penguin', 1558: 'pennies', 1559: 'penny', 1560: 'people', 1561: 'pepper', 1562: 'per', 1563: 'percetly', 1564: 'perfectly', 1565: 'perform', 1566: 'performs', 1567: 'perverted', 1568: 'peter', 1569: 'phone', 1570: 'photograph', 1571: 'photographs', 1572: 'piano', 1573: 'pick', 1574: 'picking', 1575: 'picks', 1576: 'picture', 1577: 'pictures', 1578: 'pie', 1579: 'piece', 1580: 'pies', 1581: 'piggies', 1582: 'piggy', 1583: 'pigs', 1584: 'pilchard', 1585: 'pillow', 1586: 'pineapple', 1587: 'pink', 1588: 'place', 1589: 'places', 1590: 'plain', 1591: 'plainly', 1592: 'plan', 1593: 'plane', 1594: 'planned', 1595: 'plans', 1596: 'plasticine', 1597: 'plat', 1598: 'play', 1599: 'played', 1600: 'playin', 1601: 'playing', 1602: 'playroom', 1603: 'plays', 1604: 'pleas', 1605: 'please', 1606: 'pleasin', 1607: 'pleasure', 1608: 'pneumonia', 1609: 'pocket', 1610: 'poe', 1611: 'point', 1612: 'police', 1613: 'policeman', 1614: 'policemen', 1615: 'polythene', 1616: 'pony', 1617: 'pool', 1618: 'pools', 1619: 'poop', 1620: 'poor', 1621: 'poppies', 1622: 'pornographic', 1623: 'port', 1624: 'porters', 1625: 'portrait', 1626: 'position', 1627: 'possessing', 1628: 'possessions', 1629: 'postcard', 1630: 'postcards', 1631: 'postman', 1632: 'pounds', 1633: 'pouring', 1634: 'pray', 1635: 'precisely', 1636: 'preparation', 1637: 'presents', 1638: 'press', 1639: 'pretend', 1640: 'pretty', 1641: 'pride', 1642: 'priestess', 1643: 'prized', 1644: 'problems', 1645: 'proceeded', 1646: 'production', 1647: 'promise', 1648: 'promises', 1649: 'prospects', 1650: 'protected', 1651: 'proud', 1652: 'prove', 1653: 'prrr', 1654: 'prudence', 1655: 'public', 1656: 'pulled', 1657: 'pum', 1658: 'puppy', 1659: 'put', 1660: 'puts', 1661: 'putting', 1662: 'quando', 1663: 'quarter', 1664: 'que', 1665: 'queen', 1666: 'questo', 1667: 'queue', 1668: 'qui', 1669: 'quietly', 1670: 'quit', 1671: 'quite', 1672: 'quizzical', 1673: 'r', 1674: 'raccoon', 1675: 'radiate', 1676: 'railman', 1677: 'rain', 1678: 'raincoats', 1679: 'rains', 1680: 'rainy', 1681: 'raise', 1682: 'raleigh', 1683: 'ran', 1684: 'rather', 1685: 're', 1686: 'reach', 1687: 'read', 1688: 'ready', 1689: 'real', 1690: 'realise', 1691: 'realize', 1692: 'realized', 1693: 'really', 1694: 'reason', 1695: 'recall', 1696: 'record', 1697: 'rectify', 1698: 'red', 1699: 'reel', 1700: 'refrain', 1701: 'refuse', 1702: 'regret', 1703: 'rehearsal', 1704: 'reject', 1705: 'relax', 1706: 'remain', 1707: 'remember', 1708: 'rent', 1709: 'repeat', 1710: 'replace', 1711: 'reply', 1712: 'reprise', 1713: 'reservation', 1714: 'resign', 1715: 'rest', 1716: 'resting', 1717: 'restless', 1718: 'return', 1719: 'returned', 1720: 'returning', 1721: 'review', 1722: 'revival', 1723: 'revolution', 1724: 'rhythm', 1725: 'rice', 1726: 'rich', 1727: 'ride', 1728: 'ridin', 1729: 'riding', 1730: 'rieht', 1731: 'rigby', 1732: 'right', 1733: 'rights', 1734: 'ring', 1735: 'ringing', 1736: 'ringo', 1737: 'rings', 1738: 'rise', 1739: 'risin', 1740: 'risk', 1741: 'rita', 1742: 'rival', 1743: 'river', 1744: 'road', 1745: 'roam', 1746: 'rob', 1747: 'robbin', 1748: 'robbing', 1749: 'robert', 1750: 'rock', 1751: 'rockin', 1752: 'rocking', 1753: 'rocky', 1754: 'roll', 1755: 'roller', 1756: 'rollin', 1757: 'rolling', 1758: 'romance', 1759: 'room', 1760: 'rope', 1761: 'rose', 1762: 'roses', 1763: 'round', 1764: 'roundabout', 1765: 'row', 1766: 'rug', 1767: 'ruin', 1768: 'ruins', 1769: 'rules', 1770: 'run', 1771: 'running', 1772: 'runs', 1773: 'rushes', 1774: 'ry', 1775: 'rybody', 1776: 'ryone', 1777: 'rything', 1778: 's', 1779: 'sack', 1780: 'sacraficed', 1781: 'sad', 1782: 'sadie', 1783: 'safe', 1784: 'said', 1785: 'sail', 1786: 'sailed', 1787: 'sailing', 1788: 'sake', 1789: 'sally', 1790: 'saloon', 1791: 'same', 1792: 'sand', 1793: 'sang', 1794: 'sat', 1795: 'satisfaction', 1796: 'satisfied', 1797: 'saturday', 1798: 'save', 1799: 'saved', 1800: 'saving', 1801: 'savoy', 1802: 'saw', 1803: 'sax', 1804: 'saxon', 1805: 'say', 1806: 'saying', 1807: 'says', 1808: 'scarlet', 1809: 'sce', 1810: 'scene', 1811: 'schemes', 1812: 'schon', 1813: 'schoner', 1814: 'school', 1815: 'schuld', 1816: 'science', 1817: 'scratch', 1818: 'screaming', 1819: 'screen', 1820: 'screw', 1821: 'scrimp', 1822: 'sdaeh', 1823: 'sea', 1824: 'seance', 1825: 'searchin', 1826: 'searching', 1827: 'seashell', 1828: 'seat', 1829: 'second', 1830: 'seconds', 1831: 'secret', 1832: 'see', 1833: 'seeing', 1834: 'seem', 1835: 'seemed', 1836: 'seems', 1837: 'seen', 1838: 'sees', 1839: 'sein', 1840: 'seine', 1841: 'self', 1842: 'selling', 1843: 'semoc', 1844: 'semolina', 1845: 'send', 1846: 'sending', 1847: 'sent', 1848: 'sergeant', 1849: 'sermon', 1850: 'set', 1851: 'seven', 1852: 'sexy', 1853: 'sgt', 1854: 'sh', 1855: 'sha', 1856: 'shade', 1857: 'shades', 1858: 'shadow', 1859: 'shady', 1860: 'shake', 1861: 'shall', 1862: 'share', 1863: 'shaves', 1864: 'she', 1865: 'shears', 1866: 'sheepdog', 1867: 'shelf', 1868: 'shelter', 1869: 'shimmering', 1870: 'shine', 1871: 'shines', 1872: 'shining', 1873: 'ship', 1874: 'shirt', 1875: 'shirts', 1876: 'sho', 1877: 'shoe', 1878: 'shoes', 1879: 'shoeshine', 1880: 'shook', 1881: 'shoot', 1882: 'shop', 1883: 'shore', 1884: 'short', 1885: 'shot', 1886: 'should', 1887: 'shoulder', 1888: 'shoulders', 1889: 'shout', 1890: 'shouts', 1891: 'show', 1892: 'showdown', 1893: 'showed', 1894: 'showes', 1895: 'showing', 1896: 'shown', 1897: 'shows', 1898: 'shuop', 1899: 'shy', 1900: 'side', 1901: 'sideboard', 1902: 'sie', 1903: 'sigh', 1904: 'sight', 1905: 'sign', 1906: 'silent', 1907: 'silently', 1908: 'silly', 1909: 'silver', 1910: 'sin', 1911: 'since', 1912: 'sincere', 1913: 'sincerely', 1914: 'sing', 1915: 'singer', 1916: 'singing', 1917: 'single', 1918: 'sir', 1919: 'sister', 1920: 'sit', 1921: 'sits', 1922: 'sittin', 1923: 'sitting', 1924: 'situation', 1925: 'six', 1926: 'sixty', 1927: 'skelter', 1928: 'skies', 1929: 'skin', 1930: 'skip', 1931: 'skirts', 1932: 'sky', 1933: 'slaggers', 1934: 'sleep', 1935: 'sleeping', 1936: 'sleeps', 1937: 'sleepy', 1938: 'slept', 1939: 'slide', 1940: 'sling', 1941: 'slip', 1942: 'slither', 1943: 'slow', 1944: 'slowly', 1945: 'slumbers', 1946: 'small', 1947: 'smile', 1948: 'smiles', 1949: 'smiling', 1950: 'smoke', 1951: 'smokers', 1952: 'snide', 1953: 'snores', 1954: 'snow', 1955: 'so', 1956: 'soap', 1957: 'socks', 1958: 'sofa', 1959: 'soft', 1960: 'sold', 1961: 'solid', 1962: 'solitude', 1963: 'solltest', 1964: 'solution', 1965: 'some', 1966: 'somebody', 1967: 'someday', 1968: 'somehow', 1969: 'someone', 1970: 'something', 1971: 'sometimes', 1972: 'somewhere', 1973: 'son', 1974: 'song', 1975: 'songs', 1976: 'sont', 1977: 'soon', 1978: 'sooner', 1979: 'soooo', 1980: 'soothing', 1981: 'sorrow', 1982: 'sorry', 1983: 'soul', 1984: 'sound', 1985: 'sounds', 1986: 'sour', 1987: 'south', 1988: 'southampton', 1989: 'space', 1990: 'spain', 1991: 'spaniel', 1992: 'speak', 1993: 'speaking', 1994: 'special', 1995: 'specially', 1996: 'speed', 1997: 'spend', 1998: 'spending', 1999: 'spent', 2000: 'spinal', 2001: 'spinnin', 2002: 'spinning', 2003: 'spite', 2004: 'splendid', 2005: 'split', 2006: 'spoil', 2007: 'spoke', 2008: 'spoon', 2009: 'spread', 2010: 'stairs', 2011: 'stand', 2012: 'standin', 2013: 'standing', 2014: 'stands', 2015: 'star', 2016: 'starched', 2017: 'stare', 2018: 'stared', 2019: 'staring', 2020: 'stars', 2021: 'start', 2022: 'started', 2023: 'starts', 2024: 'state', 2025: 'stating', 2026: 'station', 2027: 'stay', 2028: 'stays', 2029: 'steady', 2030: 'steal', 2031: 'stealing', 2032: 'step', 2033: 'stepping', 2034: 'stick', 2035: 'still', 2036: 'stinking', 2037: 'stirring', 2038: 'stockings', 2039: 'stone', 2040: 'stoney', 2041: 'stood', 2042: 'stop', 2043: 'stops', 2044: 'store', 2045: 'storm', 2046: 'story', 2047: 'straight', 2048: 'strange', 2049: 'strawberry', 2050: 'stream', 2051: 'street', 2052: 'stretches', 2053: 'stroll', 2054: 'strong', 2055: 'struggled', 2056: 'studied', 2057: 'stupid', 2058: 'sty', 2059: 'styes', 2060: 'style', 2061: 'submarine', 2062: 'submarines', 2063: 'suburban', 2064: 'succeed', 2065: 'success', 2066: 'such', 2067: 'sucks', 2068: 'suddenly', 2069: 'suede', 2070: 'suicidal', 2071: 'suitcase', 2072: 'summer', 2073: 'summernight', 2074: 'summersets', 2075: 'sun', 2076: 'sunday', 2077: 'sung', 2078: 'sunken', 2079: 'sunny', 2080: 'suns', 2081: 'sunshine', 2082: 'superior', 2083: 'supposed', 2084: 'suprise', 2085: 'sure', 2086: 'surely', 2087: 'surprise', 2088: 'surrender', 2089: 'swaying', 2090: 'sweat', 2091: 'sweater', 2092: 'sweaty', 2093: 'sweeping', 2094: 'sweet', 2095: 'sweeter', 2096: 'swim', 2097: 'sympathize', 2098: 'symphony', 2099: 'syndicate', 2100: 't', 2101: 'table', 2102: 'tacks', 2103: 'tail', 2104: 'take', 2105: 'taken', 2106: 'takes', 2107: 'taking', 2108: 'talk', 2109: 'talked', 2110: 'talking', 2111: 'tall', 2112: 'tan', 2113: 'tangerine', 2114: 'tango', 2115: 'tantalize', 2116: 'tantamucho', 2117: 'tart', 2118: 'taste', 2119: 'tasting', 2120: 'taught', 2121: 'tax', 2122: 'taxis', 2123: 'taxman', 2124: 'tchaikovsky', 2125: 'tea', 2126: 'teacher', 2127: 'teachers', 2128: 'tear', 2129: 'tearing', 2130: 'tears', 2131: 'teaser', 2132: 'tee', 2133: 'teen', 2134: 'telephone', 2135: 'tell', 2136: 'telling', 2137: 'tells', 2138: 'temperature', 2139: 'ten', 2140: 'tenderly', 2141: 'test', 2142: 'testimonial', 2143: 'textpert', 2144: 'than', 2145: 'thank', 2146: 'thankful', 2147: 'that', 2148: 'the', 2149: 'their', 2150: 'them', 2151: 'themselves', 2152: 'then', 2153: 'there', 2154: 'these', 2155: 'they', 2156: 'thick', 2157: 'thin', 2158: 'thing', 2159: 'things', 2160: 'think', 2161: 'thinking', 2162: 'thinks', 2163: 'thirty', 2164: 'this', 2165: 'tho', 2166: 'those', 2167: 'though', 2168: 'thought', 2169: 'thoughtless', 2170: 'thoughtlessly', 2171: 'thoughts', 2172: 'thousand', 2173: 'three', 2174: 'threw', 2175: 'thrill', 2176: 'thrilling', 2177: 'through', 2178: 'throws', 2179: 'thru', 2180: 'thumb', 2181: 'thursday', 2182: 'ticket', 2183: 'ticking', 2184: 'tide', 2185: 'tides', 2186: 'tie', 2187: 'tied', 2188: 'ties', 2189: 'tiger', 2190: 'tight', 2191: 'till', 2192: 'time', 2193: 'times', 2194: 'tired', 2195: 'to', 2196: 'today', 2197: 'toe', 2198: 'together', 2199: 'told', 2200: 'tomorrow', 2201: 'tonight', 2202: 'too', 2203: 'took', 2204: 'top', 2205: 'topping', 2206: 'touch', 2207: 'touched', 2208: 'tour', 2209: 'tow', 2210: 'tower', 2211: 'towering', 2212: 'town', 2213: 'toys', 2214: 'tracks', 2215: 'trade', 2216: 'tragic', 2217: 'trail', 2218: 'train', 2219: 'trampoline', 2220: 'trav', 2221: 'travelled', 2222: 'travelling', 2223: 'travels', 2224: 'tray', 2225: 'treasure', 2226: 'treat', 2227: 'treatin', 2228: 'treating', 2229: 'tree', 2230: 'trees', 2231: 'tremember', 2232: 'tres', 2233: 'tricks', 2234: 'tried', 2235: 'tries', 2236: 'trigger', 2237: 'trim', 2238: 'trip', 2239: 'tripper', 2240: 'trivialities', 2241: 'trolly', 2242: 'trouble', 2243: 'troubles', 2244: 'true', 2245: 'truffle', 2246: 'trust', 2247: 'truth', 2248: 'try', 2249: 'tryin', 2250: 'trying', 2251: 'tube', 2252: 'tucson', 2253: 'tuesday', 2254: 'tulips', 2255: 'tumble', 2256: 'tune', 2257: 'tuned', 2258: 'turing', 2259: 'turn', 2260: 'turned', 2261: 'turning', 2262: 'turns', 2263: 'turnstyle', 2264: 'twelve', 2265: 'twenty', 2266: 'twice', 2267: 'twist', 2268: 'two', 2269: 'u', 2270: 'uh', 2271: 'ukraine', 2272: 'um', 2273: 'uncle', 2274: 'und', 2275: 'under', 2276: 'understand', 2277: 'understands', 2278: 'understood', 2279: 'undertake', 2280: 'undying', 2281: 'unfair', 2282: 'unfold', 2283: 'unhappy', 2284: 'universe', 2285: 'unkind', 2286: 'unless', 2287: 'unpack', 2288: 'unpleasant', 2289: 'until', 2290: 'unwise', 2291: 'up', 2292: 'upon', 2293: 'upset', 2294: 'upstairs', 2295: 'uptown', 2296: 'us', 2297: 'use', 2298: 'used', 2299: 'va', 2300: 'vain', 2301: 'valentine', 2302: 'valerie', 2303: 'van', 2304: 'vanish', 2305: 've', 2306: 'velvet', 2307: 'vera', 2308: 'verdi', 2309: 'verstand', 2310: 'verstehen', 2311: 'very', 2312: 'verzeiht', 2313: 'vienna', 2314: 'view', 2315: 'views', 2316: 'voice', 2317: 'voices', 2318: 'void', 2319: 'vont', 2320: 'wail', 2321: 'wait', 2322: 'waited', 2323: 'waiting', 2324: 'waits', 2325: 'wake', 2326: 'wakes', 2327: 'walk', 2328: 'walked', 2329: 'walking', 2330: 'walks', 2331: 'wall', 2332: 'walrus', 2333: 'walter', 2334: 'waltz', 2335: 'wandering', 2336: 'wanders', 2337: 'wanna', 2338: 'want', 2339: 'wanted', 2340: 'wants', 2341: 'war', 2342: 'warm', 2343: 'warnin', 2344: 'warning', 2345: 'warst', 2346: 'warum', 2347: 'was', 2348: 'washed', 2349: 'wasn', 2350: 'wasting', 2351: 'watch', 2352: 'watchin', 2353: 'watching', 2354: 'water', 2355: 'waters', 2356: 'wave', 2357: 'waves', 2358: 'way', 2359: 'ways', 2360: 'we', 2361: 'weak', 2362: 'wear', 2363: 'wearing', 2364: 'wears', 2365: 'weather', 2366: 'weaving', 2367: 'wedding', 2368: 'wednesday', 2369: 'weeds', 2370: 'week', 2371: 'weeks', 2372: 'weep', 2373: 'weeps', 2374: 'weh', 2375: 'weight', 2376: 'welcome', 2377: 'well', 2378: 'went', 2379: 'were', 2380: 'weren', 2381: 'west', 2382: 'wet', 2383: 'whacking', 2384: 'what', 2385: 'whatever', 2386: 'when', 2387: 'whenever', 2388: 'where', 2389: 'which', 2390: 'whigwam', 2391: 'while', 2392: 'whim', 2393: 'whisper', 2394: 'white', 2395: 'who', 2396: 'whoa', 2397: 'whoah', 2398: 'whole', 2399: 'whooh', 2400: 'why', 2401: 'wicked', 2402: 'wid', 2403: 'wie', 2404: 'wife', 2405: 'wight', 2406: 'wild', 2407: 'will', 2408: 'win', 2409: 'wind', 2410: 'winding', 2411: 'window', 2412: 'windy', 2413: 'wine', 2414: 'wing', 2415: 'winging', 2416: 'wings', 2417: 'wink', 2418: 'winks', 2419: 'winter', 2420: 'wipe', 2421: 'wiping', 2422: 'wisdom', 2423: 'wish', 2424: 'wishing', 2425: 'with', 2426: 'within', 2427: 'without', 2428: 'wives', 2429: 'woke', 2430: 'woldn', 2431: 'woman', 2432: 'won', 2433: 'wond', 2434: 'wonder', 2435: 'wonderful', 2436: 'wondering', 2437: 'wonders', 2438: 'woo', 2439: 'wood', 2440: 'woos', 2441: 'word', 2442: 'words', 2443: 'wore', 2444: 'work', 2445: 'worked', 2446: 'working', 2447: 'works', 2448: 'world', 2449: 'worm', 2450: 'worries', 2451: 'worry', 2452: 'worrying', 2453: 'worse', 2454: 'worth', 2455: 'would', 2456: 'wouldn', 2457: 'wring', 2458: 'write', 2459: 'writer', 2460: 'writing', 2461: 'wrong', 2462: 'wrote', 2463: 'wusste', 2464: 'ya', 2465: 'yard', 2466: 'yawning', 2467: 'ye', 2468: 'yea', 2469: 'yeah', 2470: 'year', 2471: 'years', 2472: 'yee', 2473: 'yeh', 2474: 'yeht', 2475: 'yellow', 2476: 'yer', 2477: 'yes', 2478: 'yesterday', 2479: 'yet', 2480: 'yi', 2481: 'yoko', 2482: 'you', 2483: 'young', 2484: 'younger', 2485: 'your', 2486: 'yours', 2487: 'yourself', 2488: 'zapped', 2489: 'zoo', 2490: 'zu'}\n",
      "vocab_to_int:  {'a': 0, 'aaaaaaaahhhh': 1, 'aaaaaahhhhhh': 2, 'aaaaahhhhhhhhhh': 3, 'aaaah': 4, 'aaahhh': 5, 'able': 6, 'about': 7, 'above': 8, 'abrigado': 9, 'accidents': 10, 'aches': 11, 'acorns': 12, 'acquainted': 13, 'across': 14, 'act': 15, 'acts': 16, 'admit': 17, 'advice': 18, 'affection': 19, 'afraid': 20, 'after': 21, 'afternoon': 22, 'again': 23, 'against': 24, 'age': 25, 'ago': 26, 'agree': 27, 'ah': 28, 'ahead': 29, 'ain': 30, 'air': 31, 'al': 32, 'albert': 33, 'alerted': 34, 'all': 35, 'allan': 36, 'allein': 37, 'alley': 38, 'almost': 39, 'alone': 40, 'along': 41, 'aloud': 42, 'already': 43, 'alright': 44, 'although': 45, 'always': 46, 'am': 47, 'american': 48, 'amore': 49, 'amsterdam': 50, 'an': 51, 'and': 52, 'andern': 53, 'angel': 54, 'angry': 55, 'anna': 56, 'annoyed': 57, 'another': 58, 'answer': 59, 'any': 60, 'anybody': 61, 'anyhow': 62, 'anymore': 63, 'anyone': 64, 'anything': 65, 'anytime': 66, 'anyway': 67, 'anywhere': 68, 'apart': 69, 'apologize': 70, 'appear': 71, 'appears': 72, 'apple': 73, 'appointment': 74, 'appreciate': 75, 'are': 76, 'aren': 77, 'arise': 78, 'arizona': 79, 'armchair': 80, 'armen': 81, 'arms': 82, 'army': 83, 'around': 84, 'arrive': 85, 'arrives': 86, 'arriving': 87, 'as': 88, 'ask': 89, 'asked': 90, 'asking': 91, 'asleep': 92, 'assure': 93, 'assured': 94, 'at': 95, 'ate': 96, 'atlantic': 97, 'attractively': 98, 'attracts': 99, 'audience': 100, 'aunt': 101, 'avoid': 102, 'awake': 103, 'aware': 104, 'away': 105, 'awoke': 106, 'awoken': 107, 'ay': 108, 'b': 109, 'ba': 110, 'babe': 111, 'baby': 112, 'back': 113, 'backdoor': 114, 'backed': 115, 'backing': 116, 'bacon': 117, 'bad': 118, 'badly': 119, 'bag': 120, 'bags': 121, 'balalaika': 122, 'ball': 123, 'ballad': 124, 'band': 125, 'bang': 126, 'banker': 127, 'banks': 128, 'barber': 129, 'barrow': 130, 'based': 131, 'bath': 132, 'bathroom': 133, 'bb': 134, 'bbbbb': 135, 'bbc': 136, 'be': 137, 'beach': 138, 'beam': 139, 'beat': 140, 'beatin': 141, 'beautiful': 142, 'beauty': 143, 'became': 144, 'because': 145, 'becomes': 146, 'bed': 147, 'bedroom': 148, 'beds': 149, 'bee': 150, 'been': 151, 'beep': 152, 'bees': 153, 'beethoven': 154, 'before': 155, 'beg': 156, 'begged': 157, 'beggin': 158, 'begging': 159, 'begin': 160, 'begings': 161, 'beginning': 162, 'begins': 163, 'behave': 164, 'behind': 165, 'bei': 166, 'being': 167, 'bejust': 168, 'believe': 169, 'believing': 170, 'bell': 171, 'belle': 172, 'bells': 173, 'bellyful': 174, 'belong': 175, 'belonged': 176, 'below': 177, 'bended': 178, 'beneath': 179, 'benefit': 180, 'bent': 181, 'beside': 182, 'best': 183, 'bet': 184, 'better': 185, 'between': 186, 'beyond': 187, 'bible': 188, 'biding': 189, 'bien': 190, 'big': 191, 'bigger': 192, 'biggest': 193, 'bill': 194, 'billy': 195, 'bin': 196, 'bird': 197, 'birds': 198, 'birthday': 199, 'bishopsgate': 200, 'bist': 201, 'bit': 202, 'bits': 203, 'bla': 204, 'black': 205, 'blackbird': 206, 'blackburn': 207, 'blame': 208, 'blew': 209, 'blind': 210, 'blindly': 211, 'blink': 212, 'bloody': 213, 'blow': 214, 'blowin': 215, 'blows': 216, 'blue': 217, 'blues': 218, 'boac': 219, 'board': 220, 'boat': 221, 'bob': 222, 'bone': 223, 'book': 224, 'booked': 225, 'books': 226, 'boom': 227, 'bootlace': 228, 'boots': 229, 'bop': 230, 'born': 231, 'both': 232, 'bother': 233, 'bottle': 234, 'bottom': 235, 'bought': 236, 'bound': 237, 'bounder': 238, 'bout': 239, 'box': 240, 'boy': 241, 'boyfriend': 242, 'boys': 243, 'bra': 244, 'brain': 245, 'brand': 246, 'break': 247, 'breakfast': 248, 'breaking': 249, 'breaks': 250, 'breast': 251, 'brew': 252, 'bride': 253, 'bridge': 254, 'bright': 255, 'bring': 256, 'bringing': 257, 'brings': 258, 'broke': 259, 'broken': 260, 'brother': 261, 'brown': 262, 'built': 263, 'bulldog': 264, 'bullet': 265, 'bullfrog': 266, 'bundle': 267, 'bungalow': 268, 'buried': 269, 'burning': 270, 'burns': 271, 'burst': 272, 'bus': 273, 'busby': 274, 'business': 275, 'busy': 276, 'but': 277, 'butted': 278, 'butterflies': 279, 'buy': 280, 'buys': 281, 'by': 282, 'bye': 283, 'c': 284, 'cake': 285, 'california': 286, 'call': 287, 'called': 288, 'calling': 289, 'calls': 290, 'came': 291, 'can': 292, 'canary': 293, 'canite': 294, 'cannot': 295, 'cap': 296, 'captain': 297, 'car': 298, 'carat': 299, 'carathon': 300, 'card': 301, 'care': 302, 'cares': 303, 'caressing': 304, 'carousel': 305, 'carry': 306, 'carrying': 307, 'carve': 308, 'case': 309, 'cast': 310, 'cat': 311, 'catch': 312, 'caught': 313, 'cause': 314, 'cave': 315, 'ceiling': 316, 'celebrate': 317, 'celebrated': 318, 'celebrations': 319, 'cellophane': 320, 'cent': 321, 'certain': 322, 'certainly': 323, 'cha': 324, 'chain': 325, 'chains': 326, 'chair': 327, 'chairman': 328, 'challenge': 329, 'chance': 330, 'chances': 331, 'change': 332, 'changed': 333, 'changes': 334, 'changing': 335, 'charity': 336, 'chasing': 337, 'cheat': 338, 'check': 339, 'checked': 340, 'cherry': 341, 'child': 342, 'children': 343, 'childrens': 344, 'chip': 345, 'chocolate': 346, 'choking': 347, 'choose': 348, 'chords': 349, 'chorus': 350, 'christ': 351, 'chuck': 352, 'church': 353, 'cia': 354, 'cicce': 355, 'cigarette': 356, 'city': 357, 'class': 358, 'clean': 359, 'clear': 360, 'climb': 361, 'climbing': 362, 'clinging': 363, 'clock': 364, 'close': 365, 'closed': 366, 'closer': 367, 'closing': 368, 'clothes': 369, 'cloud': 370, 'clouds': 371, 'cloudy': 372, 'clown': 373, 'clowns': 374, 'club': 375, 'clubs': 376, 'clue': 377, 'clutching': 378, 'coaster': 379, 'coat': 380, 'coca': 381, 'cocker': 382, 'coconut': 383, 'coffee': 384, 'cola': 385, 'cold': 386, 'colder': 387, 'collapsed': 388, 'college': 389, 'colour': 390, 'colourful': 391, 'comb': 392, 'come': 393, 'comes': 394, 'comfort': 395, 'coming': 396, 'command': 397, 'compare': 398, 'compares': 399, 'complainin': 400, 'comrade': 401, 'conceive': 402, 'confusing': 403, 'congo': 404, 'constitution': 405, 'continuing': 406, 'contribution': 407, 'controlled': 408, 'conversation': 409, 'cooking': 410, 'cool': 411, 'coral': 412, 'corner': 413, 'cornflake': 414, 'corporation': 415, 'correct': 416, 'cos': 417, 'cottage': 418, 'could': 419, 'couldn': 420, 'count': 421, 'country': 422, 'couple': 423, 'course': 424, 'cows': 425, 'crabalocker': 426, 'cracker': 427, 'cracks': 428, 'crash': 429, 'crawled': 430, 'crawling': 431, 'crazy': 432, 'cream': 433, 'creep': 434, 'creeps': 435, 'creme': 436, 'cried': 437, 'cries': 438, 'crime': 439, 'cross': 440, 'crossed': 441, 'crowd': 442, 'crucify': 443, 'cruel': 444, 'cry': 445, 'crying': 446, 'cummin': 447, 'cup': 448, 'curse': 449, 'custard': 450, 'customer': 451, 'cut': 452, 'cuts': 453, 'd': 454, 'da': 455, 'daddy': 456, 'daily': 457, 'daises': 458, 'daisy': 459, 'dakota': 460, 'damn': 461, 'dan': 462, 'dance': 463, 'danced': 464, 'dancer': 465, 'dances': 466, 'dancin': 467, 'daniel': 468, 'dann': 469, 'danny': 470, 'daran': 471, 'dark': 472, 'darkness': 473, 'darlin': 474, 'darling': 475, 'darn': 476, 'darning': 477, 'das': 478, 'date': 479, 'dave': 480, 'dawn': 481, 'day': 482, 'daya': 483, 'days': 484, 'de': 485, 'dead': 486, 'dear': 487, 'deceive': 488, 'decide': 489, 'declare': 490, 'deep': 491, 'deeper': 492, 'deine': 493, 'deinen': 494, 'delay': 495, 'deliver': 496, 'demonstrate': 497, 'den': 498, 'denied': 499, 'denis': 500, 'denkt': 501, 'denn': 502, 'deny': 503, 'department': 504, 'desert': 505, 'deserve': 506, 'desmond': 507, 'dessert': 508, 'destruction': 509, 'determined': 510, 'devil': 511, 'di': 512, 'diamant': 513, 'diamond': 514, 'diamonds': 515, 'dich': 516, 'did': 517, 'didididi': 518, 'didn': 519, 'die': 520, 'died': 521, 'dies': 522, 'difference': 523, 'different': 524, 'differnt': 525, 'dig': 526, 'digging': 527, 'diller': 528, 'dime': 529, 'dinner': 530, 'dir': 531, 'direction': 532, 'dirt': 533, 'dirty': 534, 'disagree': 535, 'disappear': 536, 'disappearing': 537, 'disappointment': 538, 'disconnect': 539, 'discovered': 540, 'discreetly': 541, 'disease': 542, 'diverted': 543, 'dizzy': 544, 'dna': 545, 'do': 546, 'doc': 547, 'doch': 548, 'dock': 549, 'doctor': 550, 'does': 551, 'doesn': 552, 'dog': 553, 'doggone': 554, 'doing': 555, 'don': 556, 'donated': 557, 'done': 558, 'door': 559, 'doors': 560, 'doris': 561, 'dose': 562, 'doubt': 563, 'doubted': 564, 'dove': 565, 'down': 566, 'downstairs': 567, 'draems': 568, 'drag': 569, 'dragged': 570, 'drank': 571, 'dreadful': 572, 'dream': 573, 'dreaming': 574, 'dreams': 575, 'drehtest': 576, 'dressed': 577, 'dresses': 578, 'dressing': 579, 'drew': 580, 'drift': 581, 'drifting': 582, 'drink': 583, 'drinkin': 584, 'drinking': 585, 'dripping': 586, 'drive': 587, 'driver': 588, 'driving': 589, 'drop': 590, 'drove': 591, 'dry': 592, 'du': 593, 'duchess': 594, 'ducked': 595, 'dug': 596, 'duke': 597, 'duty': 598, 'dying': 599, 'dylan': 600, 'e': 601, 'each': 602, 'eagle': 603, 'ear': 604, 'early': 605, 'earn': 606, 'earned': 607, 'ears': 608, 'earth': 609, 'ease': 610, 'easy': 611, 'eat': 612, 'eating': 613, 'edgar': 614, 'edih': 615, 'edison': 616, 'ee': 617, 'eggman': 618, 'eggmen': 619, 'eh': 620, 'eht': 621, 'eiffel': 622, 'eight': 623, 'ein': 624, 'einer': 625, 'einmal': 626, 'eleanor': 627, 'elementary': 628, 'elephant': 629, 'elephants': 630, 'else': 631, 'em': 632, 'end': 633, 'endear': 634, 'ending': 635, 'endless': 636, 'ends': 637, 'ene': 638, 'engaged': 639, 'engine': 640, 'england': 641, 'english': 642, 'enjoy': 643, 'enjoyed': 644, 'enough': 645, 'ensemble': 646, 'entschuldigst': 647, 'equal': 648, 'equipped': 649, 'es': 650, 'escaping': 651, 'eternally': 652, 'ev': 653, 'even': 654, 'evening': 655, 'ever': 656, 'evermore': 657, 'every': 658, 'everybody': 659, 'everyday': 660, 'everyone': 661, 'everything': 662, 'everywhere': 663, 'evolution': 664, 'exactly': 665, 'except': 666, 'existence': 667, 'expert': 668, 'eye': 669, 'eyeball': 670, 'eyes': 671, 'f': 672, 'face': 673, 'faces': 674, 'fade': 675, 'faded': 676, 'fair': 677, 'fall': 678, 'falling': 679, 'famous': 680, 'fancy': 681, 'fanques': 682, 'far': 683, 'fare': 684, 'farm': 685, 'farther': 686, 'fast': 687, 'faster': 688, 'fate': 689, 'father': 690, 'fbi': 691, 'fears': 692, 'feat': 693, 'featuring': 694, 'fed': 695, 'feed': 696, 'feel': 697, 'feelin': 698, 'feeling': 699, 'feelings': 700, 'feels': 701, 'feet': 702, 'felice': 703, 'fell': 704, 'fever': 705, 'few': 706, 'fi': 707, 'fiddle': 708, 'field': 709, 'fields': 710, 'fierce': 711, 'fifty': 712, 'fight': 713, 'fighting': 714, 'fil': 715, 'fill': 716, 'filled': 717, 'filling': 718, 'film': 719, 'filter': 720, 'finally': 721, 'find': 722, 'finds': 723, 'fine': 724, 'finger': 725, 'fingertips': 726, 'fire': 727, 'fireman': 728, 'fireside': 729, 'first': 730, 'fish': 731, 'fishwife': 732, 'five': 733, 'fix': 734, 'fixing': 735, 'flat': 736, 'flattop': 737, 'flew': 738, 'flies': 739, 'flight': 740, 'flirt': 741, 'float': 742, 'floating': 743, 'floor': 744, 'flowers': 745, 'flowing': 746, 'flown': 747, 'flows': 748, 'fly': 749, 'flys': 750, 'fog': 751, 'fold': 752, 'folks': 753, 'follow': 754, 'fool': 755, 'foolin': 756, 'fooling': 757, 'foolish': 758, 'foot': 759, 'football': 760, 'footsteps': 761, 'for': 762, 'fore': 763, 'forever': 764, 'forget': 765, 'forgive': 766, 'forgotten': 767, 'forks': 768, 'form': 769, 'found': 770, 'fountain': 771, 'four': 772, 'fragrant': 773, 'france': 774, 'frantic': 775, 'free': 776, 'freely': 777, 'freu': 778, 'friday': 779, 'friend': 780, 'friends': 781, 'frightened': 782, 'froh': 783, 'from': 784, 'front': 785, 'frown': 786, 'fudge': 787, 'full': 788, 'fun': 789, 'funny': 790, 'fuse': 791, 'fussing': 792, 'future': 793, 'g': 794, 'gain': 795, 'gallery': 796, 'game': 797, 'games': 798, 'gar': 799, 'garden': 800, 'garters': 801, 'gas': 802, 'gather': 803, 'gave': 804, 'gear': 805, 'gee': 806, 'gehen': 807, 'gently': 808, 'george': 809, 'georgia': 810, 'gesehen': 811, 'gestern': 812, 'get': 813, 'getan': 814, 'gets': 815, 'getter': 816, 'getting': 817, 'gib': 818, 'gibraltar': 819, 'gideon': 820, 'gimme': 821, 'gin': 822, 'ginger': 823, 'girl': 824, 'girlfriend': 825, 'girls': 826, 'give': 827, 'gives': 828, 'givin': 829, 'giving': 830, 'glad': 831, 'glass': 832, 'glaubst': 833, 'glimmering': 834, 'glimpse': 835, 'glow': 836, 'glucklich': 837, 'go': 838, 'goats': 839, 'goes': 840, 'goin': 841, 'going': 842, 'golden': 843, 'gone': 844, 'gonna': 845, 'goo': 846, 'good': 847, 'goodbye': 848, 'goodbyes': 849, 'got': 850, 'gotta': 851, 'gown': 852, 'grabbed': 853, 'grade': 854, 'grandchildren': 855, 'grass': 856, 'grave': 857, 'greatest': 858, 'green': 859, 'greet': 860, 'greetings': 861, 'grin': 862, 'grinning': 863, 'grooving': 864, 'ground': 865, 'grow': 866, 'guaranteed': 867, 'guess': 868, 'guest': 869, 'guilty': 870, 'guitar': 871, 'gum': 872, 'gumboot': 873, 'gun': 874, 'guru': 875, 'gurus': 876, 'guy': 877, 'h': 878, 'hab': 879, 'habit': 880, 'had': 881, 'hai': 882, 'hair': 883, 'haired': 884, 'half': 885, 'hall': 886, 'hammer': 887, 'hand': 888, 'hands': 889, 'handy': 890, 'hang': 891, 'hanging': 892, 'hankerchief': 893, 'happen': 894, 'happened': 895, 'happens': 896, 'happiness': 897, 'happinness': 898, 'happy': 899, 'hard': 900, 'hardly': 901, 'hari': 902, 'harm': 903, 'harmony': 904, 'has': 905, 'hast': 906, 'hat': 907, 'hate': 908, 'hates': 909, 'have': 910, 'haven': 911, 'havin': 912, 'having': 913, 'hay': 914, 'haze': 915, 'he': 916, 'head': 917, 'headed': 918, 'heading': 919, 'heads': 920, 'health': 921, 'hear': 922, 'heard': 923, 'hearing': 924, 'hears': 925, 'heart': 926, 'hearted': 927, 'hearts': 928, 'heat': 929, 'heaven': 930, 'heavy': 931, 'heba': 932, 'heel': 933, 'hela': 934, 'held': 935, 'hello': 936, 'helloa': 937, 'help': 938, 'helping': 939, 'helps': 940, 'helter': 941, 'hendersons': 942, 'henry': 943, 'her': 944, 'here': 945, 'herself': 946, 'hewr': 947, 'hey': 948, 'hi': 949, 'hide': 950, 'hideaway': 951, 'hiding': 952, 'high': 953, 'higher': 954, 'hill': 955, 'hills': 956, 'hilt': 957, 'hilton': 958, 'him': 959, 'himself': 960, 'his': 961, 'hit': 962, 'ho': 963, 'hobnail': 964, 'hoe': 965, 'hog': 966, 'hogshead': 967, 'hold': 968, 'holding': 969, 'hole': 970, 'holes': 971, 'holiday': 972, 'holland': 973, 'hollywood': 974, 'holy': 975, 'home': 976, 'homeward': 977, 'homing': 978, 'honey': 979, 'hoo': 980, 'hoop': 981, 'hoops': 982, 'hope': 983, 'hoped': 984, 'hoping': 985, 'horse': 986, 'horses': 987, 'hot': 988, 'hour': 989, 'hourglass': 990, 'house': 991, 'how': 992, 'however': 993, 'hugs': 994, 'huh': 995, 'hula': 996, 'hum': 997, 'hung': 998, 'hunting': 999, 'hurricane': 1000, 'hurry': 1001, 'hurt': 1002, 'hurting': 1003, 'husband': 1004, 'i': 1005, 'ice': 1006, 'ich': 1007, 'if': 1008, 'ignorance': 1009, 'ihr': 1010, 'illusion': 1011, 'images': 1012, 'imagine': 1013, 'imagined': 1014, 'imitate': 1015, 'imperfect': 1016, 'important': 1017, 'impression': 1018, 'imprisoned': 1019, 'in': 1020, 'inciting': 1021, 'incredibly': 1022, 'independence': 1023, 'indicate': 1024, 'inner': 1025, 'inquire': 1026, 'insane': 1027, 'insecure': 1028, 'inside': 1029, 'inspiration': 1030, 'instead': 1031, 'institution': 1032, 'into': 1033, 'introduce': 1034, 'inverted': 1035, 'investigation': 1036, 'invitation': 1037, 'inviting': 1038, 'iron': 1039, 'is': 1040, 'isle': 1041, 'isn': 1042, 'it': 1043, 'its': 1044, 'j': 1045, 'ja': 1046, 'jack': 1047, 'jackboots': 1048, 'jai': 1049, 'jam': 1050, 'jamboree': 1051, 'jar': 1052, 'jay': 1053, 'jazz': 1054, 'jealous': 1055, 'jetzt': 1056, 'jewellers': 1057, 'jo': 1058, 'joa': 1059, 'joan': 1060, 'job': 1061, 'jobber': 1062, 'jockey': 1063, 'john': 1064, 'joint': 1065, 'jojo': 1066, 'joke': 1067, 'joker': 1068, 'jokey': 1069, 'jonah': 1070, 'jones': 1071, 'joo': 1072, 'joob': 1073, 'joy': 1074, 'jubilee': 1075, 'jude': 1076, 'judge': 1077, 'jukebox': 1078, 'julia': 1079, 'jump': 1080, 'jungle': 1081, 'junior': 1082, 'just': 1083, 'k': 1084, 'kaleidoscope': 1085, 'kann': 1086, 'kansas': 1087, 'kave': 1088, 'keep': 1089, 'keeping': 1090, 'keeps': 1091, 'kept': 1092, 'key': 1093, 'kick': 1094, 'kicking': 1095, 'kid': 1096, 'kids': 1097, 'kill': 1098, 'killer': 1099, 'kilt': 1100, 'kind': 1101, 'kindly': 1102, 'kindness': 1103, 'king': 1104, 'kircaldy': 1105, 'kiss': 1106, 'kissin': 1107, 'kissing': 1108, 'kitchen': 1109, 'kite': 1110, 'knee': 1111, 'knees': 1112, 'knew': 1113, 'knickers': 1114, 'knife': 1115, 'knit': 1116, 'knives': 1117, 'knock': 1118, 'knocking': 1119, 'know': 1120, 'knowing': 1121, 'known': 1122, 'knows': 1123, 'komm': 1124, 'krishna': 1125, 'l': 1126, 'la': 1127, 'lacking': 1128, 'lady': 1129, 'lagoon': 1130, 'lala': 1131, 'lancashire': 1132, 'land': 1133, 'lane': 1134, 'lark': 1135, 'last': 1136, 'lasted': 1137, 'lastly': 1138, 'lasts': 1139, 'latches': 1140, 'late': 1141, 'latest': 1142, 'laugh': 1143, 'laughing': 1144, 'laughs': 1145, 'laughter': 1146, 'laundromat': 1147, 'lay': 1148, 'layed': 1149, 'lazy': 1150, 'lead': 1151, 'leads': 1152, 'lear': 1153, 'learn': 1154, 'learned': 1155, 'learning': 1156, 'learns': 1157, 'leave': 1158, 'leaves': 1159, 'leaving': 1160, 'left': 1161, 'legend': 1162, 'legs': 1163, 'leisure': 1164, 'lemonade': 1165, 'lend': 1166, 'les': 1167, 'less': 1168, 'let': 1169, 'lets': 1170, 'letter': 1171, 'letters': 1172, 'licks': 1173, 'lie': 1174, 'liebt': 1175, 'lied': 1176, 'lies': 1177, 'life': 1178, 'lifetime': 1179, 'lift': 1180, 'lifting': 1181, 'light': 1182, 'lighten': 1183, 'lightning': 1184, 'lights': 1185, 'like': 1186, 'likes': 1187, 'lil': 1188, 'lime': 1189, 'limitless': 1190, 'limousine': 1191, 'line': 1192, 'ling': 1193, 'linger': 1194, 'lingers': 1195, 'lip': 1196, 'lips': 1197, 'listen': 1198, 'listening': 1199, 'lit': 1200, 'little': 1201, 'live': 1202, 'lived': 1203, 'liverpool': 1204, 'lives': 1205, 'living': 1206, 'lizard': 1207, 'lizzie': 1208, 'll': 1209, 'local': 1210, 'location': 1211, 'lock': 1212, 'locked': 1213, 'log': 1214, 'london': 1215, 'lonely': 1216, 'loner': 1217, 'long': 1218, 'longer': 1219, 'look': 1220, 'looked': 1221, 'looking': 1222, 'looks': 1223, 'lords': 1224, 'loretta': 1225, 'lorry': 1226, 'lose': 1227, 'loser': 1228, 'losing': 1229, 'lost': 1230, 'lot': 1231, 'lots': 1232, 'lotta': 1233, 'loud': 1234, 'love': 1235, 'loved': 1236, 'lovely': 1237, 'lover': 1238, 'lovers': 1239, 'loves': 1240, 'lovin': 1241, 'loving': 1242, 'low': 1243, 'luck': 1244, 'lucky': 1245, 'lucy': 1246, 'lullabye': 1247, 'lying': 1248, 'm': 1249, 'ma': 1250, 'mac': 1251, 'machine': 1252, 'mack': 1253, 'mad': 1254, 'madam': 1255, 'made': 1256, 'madly': 1257, 'madonna': 1258, 'mae': 1259, 'magazine': 1260, 'maggie': 1261, 'magic': 1262, 'magical': 1263, 'magil': 1264, 'maid': 1265, 'mail': 1266, 'majesty': 1267, 'majoring': 1268, 'make': 1269, 'makes': 1270, 'making': 1271, 'mama': 1272, 'mambo': 1273, 'man': 1274, 'manage': 1275, 'mantel': 1276, 'many': 1277, 'mao': 1278, 'march': 1279, 'marigold': 1280, 'market': 1281, 'marmalade': 1282, 'married': 1283, 'marry': 1284, 'marshmellow': 1285, 'martha': 1286, 'martin': 1287, 'marvel': 1288, 'mary': 1289, 'mask': 1290, 'match': 1291, 'matchbox': 1292, 'matches': 1293, 'matt': 1294, 'matter': 1295, 'mattered': 1296, 'max': 1297, 'maxwell': 1298, 'may': 1299, 'mayayake': 1300, 'maybe': 1301, 'mckenzie': 1302, 'me': 1303, 'meadows': 1304, 'mean': 1305, 'meander': 1306, 'meaning': 1307, 'meaningless': 1308, 'means': 1309, 'meant': 1310, 'meanwhile': 1311, 'measured': 1312, 'medicine': 1313, 'medley': 1314, 'meet': 1315, 'meeting': 1316, 'melody': 1317, 'melting': 1318, 'memories': 1319, 'men': 1320, 'mending': 1321, 'message': 1322, 'messrs': 1323, 'met': 1324, 'metaphysical': 1325, 'meter': 1326, 'mi': 1327, 'miami': 1328, 'mich': 1329, 'michelle': 1330, 'middle': 1331, 'might': 1332, 'mighty': 1333, 'miles': 1334, 'military': 1335, 'million': 1336, 'mind': 1337, 'minds': 1338, 'mine': 1339, 'minute': 1340, 'mir': 1341, 'mirrors': 1342, 'misery': 1343, 'misplace': 1344, 'miss': 1345, 'missed': 1346, 'misses': 1347, 'missing': 1348, 'mist': 1349, 'mistake': 1350, 'mister': 1351, 'misunderstanding': 1352, 'misunderstood': 1353, 'mit': 1354, 'mmm': 1355, 'mo': 1356, 'moan': 1357, 'modern': 1358, 'mojo': 1359, 'molly': 1360, 'mom': 1361, 'moment': 1362, 'moments': 1363, 'mon': 1364, 'monday': 1365, 'money': 1366, 'monkey': 1367, 'montelimat': 1368, 'mood': 1369, 'moon': 1370, 'mooning': 1371, 'moonlight': 1372, 'more': 1373, 'morining': 1374, 'mornin': 1375, 'morning': 1376, 'mornings': 1377, 'moscow': 1378, 'most': 1379, 'mother': 1380, 'motor': 1381, 'motorcar': 1382, 'mots': 1383, 'mountain': 1384, 'mountains': 1385, 'mourn': 1386, 'move': 1387, 'moved': 1388, 'movement': 1389, 'moves': 1390, 'movies': 1391, 'movin': 1392, 'moving': 1393, 'mr': 1394, 'much': 1395, 'muddy': 1396, 'multicoloured': 1397, 'mundo': 1398, 'music': 1399, 'musst': 1400, 'must': 1401, 'mustard': 1402, 'my': 1403, 'myself': 1404, 'mystery': 1405, 'n': 1406, 'na': 1407, 'naaa': 1408, 'name': 1409, 'named': 1410, 'nananana': 1411, 'nanananaaa': 1412, 'nancy': 1413, 'nasty': 1414, 'nation': 1415, 'national': 1416, 'natural': 1417, 'naturally': 1418, 'nature': 1419, 'naughty': 1420, 'nay': 1421, 'near': 1422, 'nearly': 1423, 'neck': 1424, 'need': 1425, 'needed': 1426, 'needs': 1427, 'negotiations': 1428, 'neighborhood': 1429, 'neighbors': 1430, 'nerve': 1431, 'never': 1432, 'new': 1433, 'news': 1434, 'newspaper': 1435, 'newspapers': 1436, 'next': 1437, 'niar': 1438, 'nice': 1439, 'nicht': 1440, 'nie': 1441, 'night': 1442, 'nights': 1443, 'nighttime': 1444, 'nimmst': 1445, 'nine': 1446, 'nineteen': 1447, 'no': 1448, 'nobody': 1449, 'noch': 1450, 'noise': 1451, 'none': 1452, 'north': 1453, 'northern': 1454, 'norwegian': 1455, 'nose': 1456, 'not': 1457, 'note': 1458, 'nothin': 1459, 'nothing': 1460, 'notice': 1461, 'noticed': 1462, 'novel': 1463, 'now': 1464, 'nowhere': 1465, 'number': 1466, 'nun': 1467, 'nur': 1468, 'nurse': 1469, 'o': 1470, 'oa': 1471, 'oan': 1472, 'ob': 1473, 'obla': 1474, 'oblada': 1475, 'obladi': 1476, 'obscene': 1477, 'ocean': 1478, 'oceanchild': 1479, 'octopus': 1480, 'of': 1481, 'off': 1482, 'often': 1483, 'oh': 1484, 'ohh': 1485, 'ok': 1486, 'ol': 1487, 'old': 1488, 'older': 1489, 'om': 1490, 'on': 1491, 'once': 1492, 'one': 1493, 'onion': 1494, 'only': 1495, 'ono': 1496, 'oo': 1497, 'ooh': 1498, 'oooh': 1499, 'opaque': 1500, 'open': 1501, 'opened': 1502, 'or': 1503, 'orange': 1504, 'oscar': 1505, 'other': 1506, 'ought': 1507, 'oughta': 1508, 'ould': 1509, 'our': 1510, 'ours': 1511, 'ourselves': 1512, 'out': 1513, 'outside': 1514, 'over': 1515, 'overnight': 1516, 'overtime': 1517, 'ow': 1518, 'own': 1519, 'owned': 1520, 'owww': 1521, 'p': 1522, 'pablo': 1523, 'pages': 1524, 'paid': 1525, 'pain': 1526, 'painting': 1527, 'pam': 1528, 'pane': 1529, 'paparazzi': 1530, 'paper': 1531, 'paperback': 1532, 'papers': 1533, 'paramucho': 1534, 'parasol': 1535, 'paris': 1536, 'park': 1537, 'parking': 1538, 'parlour': 1539, 'part': 1540, 'parted': 1541, 'partner': 1542, 'party': 1543, 'pass': 1544, 'passed': 1545, 'past': 1546, 'patiently': 1547, 'paul': 1548, 'pay': 1549, 'peace': 1550, 'peaches': 1551, 'peaked': 1552, 'peanuts': 1553, 'peasant': 1554, 'peep': 1555, 'penetrate': 1556, 'penguin': 1557, 'pennies': 1558, 'penny': 1559, 'people': 1560, 'pepper': 1561, 'per': 1562, 'percetly': 1563, 'perfectly': 1564, 'perform': 1565, 'performs': 1566, 'perverted': 1567, 'peter': 1568, 'phone': 1569, 'photograph': 1570, 'photographs': 1571, 'piano': 1572, 'pick': 1573, 'picking': 1574, 'picks': 1575, 'picture': 1576, 'pictures': 1577, 'pie': 1578, 'piece': 1579, 'pies': 1580, 'piggies': 1581, 'piggy': 1582, 'pigs': 1583, 'pilchard': 1584, 'pillow': 1585, 'pineapple': 1586, 'pink': 1587, 'place': 1588, 'places': 1589, 'plain': 1590, 'plainly': 1591, 'plan': 1592, 'plane': 1593, 'planned': 1594, 'plans': 1595, 'plasticine': 1596, 'plat': 1597, 'play': 1598, 'played': 1599, 'playin': 1600, 'playing': 1601, 'playroom': 1602, 'plays': 1603, 'pleas': 1604, 'please': 1605, 'pleasin': 1606, 'pleasure': 1607, 'pneumonia': 1608, 'pocket': 1609, 'poe': 1610, 'point': 1611, 'police': 1612, 'policeman': 1613, 'policemen': 1614, 'polythene': 1615, 'pony': 1616, 'pool': 1617, 'pools': 1618, 'poop': 1619, 'poor': 1620, 'poppies': 1621, 'pornographic': 1622, 'port': 1623, 'porters': 1624, 'portrait': 1625, 'position': 1626, 'possessing': 1627, 'possessions': 1628, 'postcard': 1629, 'postcards': 1630, 'postman': 1631, 'pounds': 1632, 'pouring': 1633, 'pray': 1634, 'precisely': 1635, 'preparation': 1636, 'presents': 1637, 'press': 1638, 'pretend': 1639, 'pretty': 1640, 'pride': 1641, 'priestess': 1642, 'prized': 1643, 'problems': 1644, 'proceeded': 1645, 'production': 1646, 'promise': 1647, 'promises': 1648, 'prospects': 1649, 'protected': 1650, 'proud': 1651, 'prove': 1652, 'prrr': 1653, 'prudence': 1654, 'public': 1655, 'pulled': 1656, 'pum': 1657, 'puppy': 1658, 'put': 1659, 'puts': 1660, 'putting': 1661, 'quando': 1662, 'quarter': 1663, 'que': 1664, 'queen': 1665, 'questo': 1666, 'queue': 1667, 'qui': 1668, 'quietly': 1669, 'quit': 1670, 'quite': 1671, 'quizzical': 1672, 'r': 1673, 'raccoon': 1674, 'radiate': 1675, 'railman': 1676, 'rain': 1677, 'raincoats': 1678, 'rains': 1679, 'rainy': 1680, 'raise': 1681, 'raleigh': 1682, 'ran': 1683, 'rather': 1684, 're': 1685, 'reach': 1686, 'read': 1687, 'ready': 1688, 'real': 1689, 'realise': 1690, 'realize': 1691, 'realized': 1692, 'really': 1693, 'reason': 1694, 'recall': 1695, 'record': 1696, 'rectify': 1697, 'red': 1698, 'reel': 1699, 'refrain': 1700, 'refuse': 1701, 'regret': 1702, 'rehearsal': 1703, 'reject': 1704, 'relax': 1705, 'remain': 1706, 'remember': 1707, 'rent': 1708, 'repeat': 1709, 'replace': 1710, 'reply': 1711, 'reprise': 1712, 'reservation': 1713, 'resign': 1714, 'rest': 1715, 'resting': 1716, 'restless': 1717, 'return': 1718, 'returned': 1719, 'returning': 1720, 'review': 1721, 'revival': 1722, 'revolution': 1723, 'rhythm': 1724, 'rice': 1725, 'rich': 1726, 'ride': 1727, 'ridin': 1728, 'riding': 1729, 'rieht': 1730, 'rigby': 1731, 'right': 1732, 'rights': 1733, 'ring': 1734, 'ringing': 1735, 'ringo': 1736, 'rings': 1737, 'rise': 1738, 'risin': 1739, 'risk': 1740, 'rita': 1741, 'rival': 1742, 'river': 1743, 'road': 1744, 'roam': 1745, 'rob': 1746, 'robbin': 1747, 'robbing': 1748, 'robert': 1749, 'rock': 1750, 'rockin': 1751, 'rocking': 1752, 'rocky': 1753, 'roll': 1754, 'roller': 1755, 'rollin': 1756, 'rolling': 1757, 'romance': 1758, 'room': 1759, 'rope': 1760, 'rose': 1761, 'roses': 1762, 'round': 1763, 'roundabout': 1764, 'row': 1765, 'rug': 1766, 'ruin': 1767, 'ruins': 1768, 'rules': 1769, 'run': 1770, 'running': 1771, 'runs': 1772, 'rushes': 1773, 'ry': 1774, 'rybody': 1775, 'ryone': 1776, 'rything': 1777, 's': 1778, 'sack': 1779, 'sacraficed': 1780, 'sad': 1781, 'sadie': 1782, 'safe': 1783, 'said': 1784, 'sail': 1785, 'sailed': 1786, 'sailing': 1787, 'sake': 1788, 'sally': 1789, 'saloon': 1790, 'same': 1791, 'sand': 1792, 'sang': 1793, 'sat': 1794, 'satisfaction': 1795, 'satisfied': 1796, 'saturday': 1797, 'save': 1798, 'saved': 1799, 'saving': 1800, 'savoy': 1801, 'saw': 1802, 'sax': 1803, 'saxon': 1804, 'say': 1805, 'saying': 1806, 'says': 1807, 'scarlet': 1808, 'sce': 1809, 'scene': 1810, 'schemes': 1811, 'schon': 1812, 'schoner': 1813, 'school': 1814, 'schuld': 1815, 'science': 1816, 'scratch': 1817, 'screaming': 1818, 'screen': 1819, 'screw': 1820, 'scrimp': 1821, 'sdaeh': 1822, 'sea': 1823, 'seance': 1824, 'searchin': 1825, 'searching': 1826, 'seashell': 1827, 'seat': 1828, 'second': 1829, 'seconds': 1830, 'secret': 1831, 'see': 1832, 'seeing': 1833, 'seem': 1834, 'seemed': 1835, 'seems': 1836, 'seen': 1837, 'sees': 1838, 'sein': 1839, 'seine': 1840, 'self': 1841, 'selling': 1842, 'semoc': 1843, 'semolina': 1844, 'send': 1845, 'sending': 1846, 'sent': 1847, 'sergeant': 1848, 'sermon': 1849, 'set': 1850, 'seven': 1851, 'sexy': 1852, 'sgt': 1853, 'sh': 1854, 'sha': 1855, 'shade': 1856, 'shades': 1857, 'shadow': 1858, 'shady': 1859, 'shake': 1860, 'shall': 1861, 'share': 1862, 'shaves': 1863, 'she': 1864, 'shears': 1865, 'sheepdog': 1866, 'shelf': 1867, 'shelter': 1868, 'shimmering': 1869, 'shine': 1870, 'shines': 1871, 'shining': 1872, 'ship': 1873, 'shirt': 1874, 'shirts': 1875, 'sho': 1876, 'shoe': 1877, 'shoes': 1878, 'shoeshine': 1879, 'shook': 1880, 'shoot': 1881, 'shop': 1882, 'shore': 1883, 'short': 1884, 'shot': 1885, 'should': 1886, 'shoulder': 1887, 'shoulders': 1888, 'shout': 1889, 'shouts': 1890, 'show': 1891, 'showdown': 1892, 'showed': 1893, 'showes': 1894, 'showing': 1895, 'shown': 1896, 'shows': 1897, 'shuop': 1898, 'shy': 1899, 'side': 1900, 'sideboard': 1901, 'sie': 1902, 'sigh': 1903, 'sight': 1904, 'sign': 1905, 'silent': 1906, 'silently': 1907, 'silly': 1908, 'silver': 1909, 'sin': 1910, 'since': 1911, 'sincere': 1912, 'sincerely': 1913, 'sing': 1914, 'singer': 1915, 'singing': 1916, 'single': 1917, 'sir': 1918, 'sister': 1919, 'sit': 1920, 'sits': 1921, 'sittin': 1922, 'sitting': 1923, 'situation': 1924, 'six': 1925, 'sixty': 1926, 'skelter': 1927, 'skies': 1928, 'skin': 1929, 'skip': 1930, 'skirts': 1931, 'sky': 1932, 'slaggers': 1933, 'sleep': 1934, 'sleeping': 1935, 'sleeps': 1936, 'sleepy': 1937, 'slept': 1938, 'slide': 1939, 'sling': 1940, 'slip': 1941, 'slither': 1942, 'slow': 1943, 'slowly': 1944, 'slumbers': 1945, 'small': 1946, 'smile': 1947, 'smiles': 1948, 'smiling': 1949, 'smoke': 1950, 'smokers': 1951, 'snide': 1952, 'snores': 1953, 'snow': 1954, 'so': 1955, 'soap': 1956, 'socks': 1957, 'sofa': 1958, 'soft': 1959, 'sold': 1960, 'solid': 1961, 'solitude': 1962, 'solltest': 1963, 'solution': 1964, 'some': 1965, 'somebody': 1966, 'someday': 1967, 'somehow': 1968, 'someone': 1969, 'something': 1970, 'sometimes': 1971, 'somewhere': 1972, 'son': 1973, 'song': 1974, 'songs': 1975, 'sont': 1976, 'soon': 1977, 'sooner': 1978, 'soooo': 1979, 'soothing': 1980, 'sorrow': 1981, 'sorry': 1982, 'soul': 1983, 'sound': 1984, 'sounds': 1985, 'sour': 1986, 'south': 1987, 'southampton': 1988, 'space': 1989, 'spain': 1990, 'spaniel': 1991, 'speak': 1992, 'speaking': 1993, 'special': 1994, 'specially': 1995, 'speed': 1996, 'spend': 1997, 'spending': 1998, 'spent': 1999, 'spinal': 2000, 'spinnin': 2001, 'spinning': 2002, 'spite': 2003, 'splendid': 2004, 'split': 2005, 'spoil': 2006, 'spoke': 2007, 'spoon': 2008, 'spread': 2009, 'stairs': 2010, 'stand': 2011, 'standin': 2012, 'standing': 2013, 'stands': 2014, 'star': 2015, 'starched': 2016, 'stare': 2017, 'stared': 2018, 'staring': 2019, 'stars': 2020, 'start': 2021, 'started': 2022, 'starts': 2023, 'state': 2024, 'stating': 2025, 'station': 2026, 'stay': 2027, 'stays': 2028, 'steady': 2029, 'steal': 2030, 'stealing': 2031, 'step': 2032, 'stepping': 2033, 'stick': 2034, 'still': 2035, 'stinking': 2036, 'stirring': 2037, 'stockings': 2038, 'stone': 2039, 'stoney': 2040, 'stood': 2041, 'stop': 2042, 'stops': 2043, 'store': 2044, 'storm': 2045, 'story': 2046, 'straight': 2047, 'strange': 2048, 'strawberry': 2049, 'stream': 2050, 'street': 2051, 'stretches': 2052, 'stroll': 2053, 'strong': 2054, 'struggled': 2055, 'studied': 2056, 'stupid': 2057, 'sty': 2058, 'styes': 2059, 'style': 2060, 'submarine': 2061, 'submarines': 2062, 'suburban': 2063, 'succeed': 2064, 'success': 2065, 'such': 2066, 'sucks': 2067, 'suddenly': 2068, 'suede': 2069, 'suicidal': 2070, 'suitcase': 2071, 'summer': 2072, 'summernight': 2073, 'summersets': 2074, 'sun': 2075, 'sunday': 2076, 'sung': 2077, 'sunken': 2078, 'sunny': 2079, 'suns': 2080, 'sunshine': 2081, 'superior': 2082, 'supposed': 2083, 'suprise': 2084, 'sure': 2085, 'surely': 2086, 'surprise': 2087, 'surrender': 2088, 'swaying': 2089, 'sweat': 2090, 'sweater': 2091, 'sweaty': 2092, 'sweeping': 2093, 'sweet': 2094, 'sweeter': 2095, 'swim': 2096, 'sympathize': 2097, 'symphony': 2098, 'syndicate': 2099, 't': 2100, 'table': 2101, 'tacks': 2102, 'tail': 2103, 'take': 2104, 'taken': 2105, 'takes': 2106, 'taking': 2107, 'talk': 2108, 'talked': 2109, 'talking': 2110, 'tall': 2111, 'tan': 2112, 'tangerine': 2113, 'tango': 2114, 'tantalize': 2115, 'tantamucho': 2116, 'tart': 2117, 'taste': 2118, 'tasting': 2119, 'taught': 2120, 'tax': 2121, 'taxis': 2122, 'taxman': 2123, 'tchaikovsky': 2124, 'tea': 2125, 'teacher': 2126, 'teachers': 2127, 'tear': 2128, 'tearing': 2129, 'tears': 2130, 'teaser': 2131, 'tee': 2132, 'teen': 2133, 'telephone': 2134, 'tell': 2135, 'telling': 2136, 'tells': 2137, 'temperature': 2138, 'ten': 2139, 'tenderly': 2140, 'test': 2141, 'testimonial': 2142, 'textpert': 2143, 'than': 2144, 'thank': 2145, 'thankful': 2146, 'that': 2147, 'the': 2148, 'their': 2149, 'them': 2150, 'themselves': 2151, 'then': 2152, 'there': 2153, 'these': 2154, 'they': 2155, 'thick': 2156, 'thin': 2157, 'thing': 2158, 'things': 2159, 'think': 2160, 'thinking': 2161, 'thinks': 2162, 'thirty': 2163, 'this': 2164, 'tho': 2165, 'those': 2166, 'though': 2167, 'thought': 2168, 'thoughtless': 2169, 'thoughtlessly': 2170, 'thoughts': 2171, 'thousand': 2172, 'three': 2173, 'threw': 2174, 'thrill': 2175, 'thrilling': 2176, 'through': 2177, 'throws': 2178, 'thru': 2179, 'thumb': 2180, 'thursday': 2181, 'ticket': 2182, 'ticking': 2183, 'tide': 2184, 'tides': 2185, 'tie': 2186, 'tied': 2187, 'ties': 2188, 'tiger': 2189, 'tight': 2190, 'till': 2191, 'time': 2192, 'times': 2193, 'tired': 2194, 'to': 2195, 'today': 2196, 'toe': 2197, 'together': 2198, 'told': 2199, 'tomorrow': 2200, 'tonight': 2201, 'too': 2202, 'took': 2203, 'top': 2204, 'topping': 2205, 'touch': 2206, 'touched': 2207, 'tour': 2208, 'tow': 2209, 'tower': 2210, 'towering': 2211, 'town': 2212, 'toys': 2213, 'tracks': 2214, 'trade': 2215, 'tragic': 2216, 'trail': 2217, 'train': 2218, 'trampoline': 2219, 'trav': 2220, 'travelled': 2221, 'travelling': 2222, 'travels': 2223, 'tray': 2224, 'treasure': 2225, 'treat': 2226, 'treatin': 2227, 'treating': 2228, 'tree': 2229, 'trees': 2230, 'tremember': 2231, 'tres': 2232, 'tricks': 2233, 'tried': 2234, 'tries': 2235, 'trigger': 2236, 'trim': 2237, 'trip': 2238, 'tripper': 2239, 'trivialities': 2240, 'trolly': 2241, 'trouble': 2242, 'troubles': 2243, 'true': 2244, 'truffle': 2245, 'trust': 2246, 'truth': 2247, 'try': 2248, 'tryin': 2249, 'trying': 2250, 'tube': 2251, 'tucson': 2252, 'tuesday': 2253, 'tulips': 2254, 'tumble': 2255, 'tune': 2256, 'tuned': 2257, 'turing': 2258, 'turn': 2259, 'turned': 2260, 'turning': 2261, 'turns': 2262, 'turnstyle': 2263, 'twelve': 2264, 'twenty': 2265, 'twice': 2266, 'twist': 2267, 'two': 2268, 'u': 2269, 'uh': 2270, 'ukraine': 2271, 'um': 2272, 'uncle': 2273, 'und': 2274, 'under': 2275, 'understand': 2276, 'understands': 2277, 'understood': 2278, 'undertake': 2279, 'undying': 2280, 'unfair': 2281, 'unfold': 2282, 'unhappy': 2283, 'universe': 2284, 'unkind': 2285, 'unless': 2286, 'unpack': 2287, 'unpleasant': 2288, 'until': 2289, 'unwise': 2290, 'up': 2291, 'upon': 2292, 'upset': 2293, 'upstairs': 2294, 'uptown': 2295, 'us': 2296, 'use': 2297, 'used': 2298, 'va': 2299, 'vain': 2300, 'valentine': 2301, 'valerie': 2302, 'van': 2303, 'vanish': 2304, 've': 2305, 'velvet': 2306, 'vera': 2307, 'verdi': 2308, 'verstand': 2309, 'verstehen': 2310, 'very': 2311, 'verzeiht': 2312, 'vienna': 2313, 'view': 2314, 'views': 2315, 'voice': 2316, 'voices': 2317, 'void': 2318, 'vont': 2319, 'wail': 2320, 'wait': 2321, 'waited': 2322, 'waiting': 2323, 'waits': 2324, 'wake': 2325, 'wakes': 2326, 'walk': 2327, 'walked': 2328, 'walking': 2329, 'walks': 2330, 'wall': 2331, 'walrus': 2332, 'walter': 2333, 'waltz': 2334, 'wandering': 2335, 'wanders': 2336, 'wanna': 2337, 'want': 2338, 'wanted': 2339, 'wants': 2340, 'war': 2341, 'warm': 2342, 'warnin': 2343, 'warning': 2344, 'warst': 2345, 'warum': 2346, 'was': 2347, 'washed': 2348, 'wasn': 2349, 'wasting': 2350, 'watch': 2351, 'watchin': 2352, 'watching': 2353, 'water': 2354, 'waters': 2355, 'wave': 2356, 'waves': 2357, 'way': 2358, 'ways': 2359, 'we': 2360, 'weak': 2361, 'wear': 2362, 'wearing': 2363, 'wears': 2364, 'weather': 2365, 'weaving': 2366, 'wedding': 2367, 'wednesday': 2368, 'weeds': 2369, 'week': 2370, 'weeks': 2371, 'weep': 2372, 'weeps': 2373, 'weh': 2374, 'weight': 2375, 'welcome': 2376, 'well': 2377, 'went': 2378, 'were': 2379, 'weren': 2380, 'west': 2381, 'wet': 2382, 'whacking': 2383, 'what': 2384, 'whatever': 2385, 'when': 2386, 'whenever': 2387, 'where': 2388, 'which': 2389, 'whigwam': 2390, 'while': 2391, 'whim': 2392, 'whisper': 2393, 'white': 2394, 'who': 2395, 'whoa': 2396, 'whoah': 2397, 'whole': 2398, 'whooh': 2399, 'why': 2400, 'wicked': 2401, 'wid': 2402, 'wie': 2403, 'wife': 2404, 'wight': 2405, 'wild': 2406, 'will': 2407, 'win': 2408, 'wind': 2409, 'winding': 2410, 'window': 2411, 'windy': 2412, 'wine': 2413, 'wing': 2414, 'winging': 2415, 'wings': 2416, 'wink': 2417, 'winks': 2418, 'winter': 2419, 'wipe': 2420, 'wiping': 2421, 'wisdom': 2422, 'wish': 2423, 'wishing': 2424, 'with': 2425, 'within': 2426, 'without': 2427, 'wives': 2428, 'woke': 2429, 'woldn': 2430, 'woman': 2431, 'won': 2432, 'wond': 2433, 'wonder': 2434, 'wonderful': 2435, 'wondering': 2436, 'wonders': 2437, 'woo': 2438, 'wood': 2439, 'woos': 2440, 'word': 2441, 'words': 2442, 'wore': 2443, 'work': 2444, 'worked': 2445, 'working': 2446, 'works': 2447, 'world': 2448, 'worm': 2449, 'worries': 2450, 'worry': 2451, 'worrying': 2452, 'worse': 2453, 'worth': 2454, 'would': 2455, 'wouldn': 2456, 'wring': 2457, 'write': 2458, 'writer': 2459, 'writing': 2460, 'wrong': 2461, 'wrote': 2462, 'wusste': 2463, 'ya': 2464, 'yard': 2465, 'yawning': 2466, 'ye': 2467, 'yea': 2468, 'yeah': 2469, 'year': 2470, 'years': 2471, 'yee': 2472, 'yeh': 2473, 'yeht': 2474, 'yellow': 2475, 'yer': 2476, 'yes': 2477, 'yesterday': 2478, 'yet': 2479, 'yi': 2480, 'yoko': 2481, 'you': 2482, 'young': 2483, 'younger': 2484, 'your': 2485, 'yours': 2486, 'yourself': 2487, 'zapped': 2488, 'zoo': 2489, 'zu': 2490}\n",
      "Epoch 1\n",
      "9/9 [==============================] - 9s 563ms/step - loss: 7.1259 - accuracy: 0.0385\n",
      "this is start_string:  zapped\n",
      "this is start_tokens:  [2488]\n",
      "this is x:  [[2488    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005] \n",
      " token_generated:  ['i']\n",
      "generated text:  zapped i \n",
      "this is x:  [[2488 1005    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005] \n",
      " token_generated:  ['i', 'i']\n",
      "generated text:  zapped i i \n",
      "this is x:  [[2488 1005 1005    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i']\n",
      "generated text:  zapped i i i \n",
      "this is x:  [[2488 1005 1005 1005    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005    0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005    0    0    0]]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005    0    0]]\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005    0]]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "this is x:  [[2488 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005 1005\n",
      "  1005 1005 1005 1005 1005 1005 1005 1005]]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "argmaxes: \n",
      " [1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005]\n",
      "argmaxes[np.argmax(np.array(argmaxes))]: 1005\n",
      "best token:  i \n",
      " start_tokens:  [2488, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005, 1005] \n",
      " token_generated:  ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n",
      "generated text:  zapped i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "random_text:  None\n",
      "Epoch 2\n",
      "9/9 [==============================] - 5s 539ms/step - loss: 5.8302 - accuracy: 0.0583\n",
      "this is start_string:  None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\conno\\OneDrive\\Desktop\\Spring 2023\\CS424\\CS424-525-Deep-learning\\Lab_4\\Project4_Shell.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model \u001b[39m=\u001b[39m TransformerModel(\u001b[39mlen\u001b[39m(vocab))\u001b[39m.\u001b[39mcreate_model()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model \u001b[39m=\u001b[39m train_model(model,x[:,:],y[:,:],vocab,epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\conno\\OneDrive\\Desktop\\Spring 2023\\CS424\\CS424-525-Deep-learning\\Lab_4\\Project4_Shell.ipynb Cell 14\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, x, y, vocab, epochs)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39mfit(x, y, epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# # # Generate text\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# random_text = GT.generate_random_text(random_text)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# print(\"random_text: \", random_text)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m random_text \u001b[39m=\u001b[39m GT\u001b[39m.\u001b[39;49mgenerate_text(random_text)  \u001b[39m#doenst get past here\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mrandom_text: \u001b[39m\u001b[39m\"\u001b[39m, random_text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# random_text = GenerateText.generate_random_text(100)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\conno\\OneDrive\\Desktop\\Spring 2023\\CS424\\CS424-525-Deep-learning\\Lab_4\\Project4_Shell.ipynb Cell 14\u001b[0m in \u001b[0;36mGenerateText.generate_text\u001b[1;34m(self, start_string, num_generate)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_text\u001b[39m(\u001b[39mself\u001b[39m, start_string, num_generate\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m#start_tokens = [_ for _ in start_string]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mthis is start_string: \u001b[39m\u001b[39m'\u001b[39m, start_string)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     start_tokens \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_to_int[word] \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m start_string\u001b[39m.\u001b[39;49msplit()]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mthis is start_tokens: \u001b[39m\u001b[39m'\u001b[39m, start_tokens)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/conno/OneDrive/Desktop/Spring%202023/CS424/CS424-525-Deep-learning/Lab_4/Project4_Shell.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     maxlen \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# clean the data\n",
    "x,y,vocab = DataSet(\"beatles.txt\", 64).create_dataset()\n",
    "# print(vocab[-10:])\n",
    "# print(x[:,-1])\n",
    "# print(y[:,-1])\n",
    "print(\"len(vocab):\", len(vocab))\n",
    "# print(\"Voab: \", vocab)\n",
    "model = TransformerModel(len(vocab)).create_model()\n",
    "\n",
    "# Train the model\n",
    "model = train_model(model,x[:,:],y[:,:],vocab,epochs=50)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "658fa81b",
   "metadata": {},
   "source": [
    "\n",
    "# Report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7b723a2",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6855b442",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c41dc86",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3812e555",
   "metadata": {},
   "source": [
    "## How to Run Code\n",
    "\n",
    "Please include any special libraries and list your tf version here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
